{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "hw3p2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MDIKA4mlc_0Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7eb25df-4541-4739-a2e9-69a4074d4084"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat Apr 10 14:19:26 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   37C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONaMkxYs6dm7",
        "outputId": "ee34447b-4814-42ee-b382-366fd8a731da"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HynwwcKK2Nc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34b7218b-644f-47a9-bbf9-5b867b850e1f"
      },
      "source": [
        "# %load phoneme_filename\n",
        "# Phoneme Map\n",
        "N_PHONEMES = 41\n",
        "PHONEME_LIST = [\n",
        "    \" \",\n",
        "    \"SIL\",\n",
        "    \"SPN\",\n",
        "    \"AA\",\n",
        "    \"AE\",\n",
        "    \"AH\",\n",
        "    \"AO\",\n",
        "    \"AW\",\n",
        "    \"AY\",\n",
        "    \"B\",\n",
        "    \"CH\",\n",
        "    \"D\",\n",
        "    \"DH\",\n",
        "    \"EH\",\n",
        "    \"ER\",\n",
        "    \"EY\",\n",
        "    \"F\",\n",
        "    \"G\",\n",
        "    \"H\",\n",
        "    \"IH\",\n",
        "    \"IY\",\n",
        "    \"JH\",\n",
        "    \"K\",\n",
        "    \"L\",\n",
        "    \"M\",\n",
        "    \"N\",\n",
        "    \"NG\",\n",
        "    \"OW\",\n",
        "    \"OY\",\n",
        "    \"P\",\n",
        "    \"R\",\n",
        "    \"S\",\n",
        "    \"SH\",\n",
        "    \"T\",\n",
        "    \"TH\",\n",
        "    \"UH\",\n",
        "    \"UW\",\n",
        "    \"V\",\n",
        "    \"W\",\n",
        "    \"Y\",\n",
        "    \"Z\",\n",
        "    \"ZH\"\n",
        "]\n",
        "\n",
        "PHONEME_MAP = [\n",
        "    \" \",\n",
        "    \".\", #SIL\n",
        "    \"!\", #SPN\n",
        "    \"a\", #AA\n",
        "    \"A\", #AE\n",
        "    \"h\", #AH\n",
        "    \"o\", #AO\n",
        "    \"w\", #AW\n",
        "    \"y\", #AY\n",
        "    \"b\", #B\n",
        "    \"c\", #CH\n",
        "    \"d\", #D\n",
        "    \"D\", #DH\n",
        "    \"e\", #EH\n",
        "    \"r\", #ER\n",
        "    \"E\", #EY\n",
        "    \"f\", #F\n",
        "    \"g\", #G\n",
        "    \"H\", #H\n",
        "    \"i\", #IH \n",
        "    \"I\", #IY\n",
        "    \"j\", #JH\n",
        "    \"k\", #K\n",
        "    \"l\", #L\n",
        "    \"m\", #M\n",
        "    \"n\", #N\n",
        "    \"N\", #NG\n",
        "    \"O\", #OW\n",
        "    \"Y\", #OY\n",
        "    \"p\", #P \n",
        "    \"R\", #R\n",
        "    \"s\", #S\n",
        "    \"S\", #SH\n",
        "    \"t\", #T\n",
        "    \"T\", #TH\n",
        "    \"u\", #UH\n",
        "    \"U\", #UW\n",
        "    \"v\", #V\n",
        "    \"W\", #W\n",
        "    \"?\", #Y\n",
        "    \"z\", #Z\n",
        "    \"Z\" #ZH\n",
        "]\n",
        "\n",
        "assert len(PHONEME_LIST) == len(PHONEME_MAP)\n",
        "assert len(set(PHONEME_MAP)) == len(PHONEME_MAP)\n",
        "\n",
        "print(len(PHONEME_LIST))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n-T4Wel66ihn"
      },
      "source": [
        "BASE_PATH = \"/content/gdrive/MyDrive/Kaggle/hw3p2/\"\n",
        "DATA_PATH = BASE_PATH + \"data/\"\n",
        "MODEL_PATH = BASE_PATH + \"models/\"\n",
        "PREDICTION_PATH = BASE_PATH + \"predictions/\""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjXvxEW46iaH"
      },
      "source": [
        "# Files from drive\n",
        "train_filename = DATA_PATH + \"train.npy\"\n",
        "train_labels_filename = DATA_PATH + \"train_labels.npy\"\n",
        "\n",
        "dev_filename = DATA_PATH + \"dev.npy\"\n",
        "dev_labels_filename = DATA_PATH + \"dev_labels.npy\"\n",
        "\n",
        "test_filename = DATA_PATH + \"test.npy\"\n",
        "\n",
        "phoneme_filename = DATA_PATH + \"phoneme_list.py\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLtp3q4MBQ0o"
      },
      "source": [
        ""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMI9gERSIKTu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4095ba9d-feed-4f91-f06b-194c1d38e39f"
      },
      "source": [
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!cd ctcdecode && pip install .\n",
        "\n",
        "!pip install python-Levenshtein"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ctcdecode'...\n",
            "remote: Enumerating objects: 1063, done.\u001b[K\n",
            "remote: Total 1063 (delta 0), reused 0 (delta 0), pack-reused 1063\u001b[K\n",
            "Receiving objects: 100% (1063/1063), 759.71 KiB | 5.67 MiB/s, done.\n",
            "Resolving deltas: 100% (513/513), done.\n",
            "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
            "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
            "Cloning into '/content/ctcdecode/third_party/ThreadPool'...\n",
            "remote: Enumerating objects: 82, done.        \n",
            "remote: Total 82 (delta 0), reused 0 (delta 0), pack-reused 82        \n",
            "Cloning into '/content/ctcdecode/third_party/kenlm'...\n",
            "remote: Enumerating objects: 13687, done.        \n",
            "remote: Total 13687 (delta 0), reused 0 (delta 0), pack-reused 13687        \n",
            "Receiving objects: 100% (13687/13687), 5.46 MiB | 10.69 MiB/s, done.\n",
            "Resolving deltas: 100% (7880/7880), done.\n",
            "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
            "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
            "Processing /content/ctcdecode\n",
            "Building wheels for collected packages: ctcdecode\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ctcdecode: filename=ctcdecode-1.0.2-cp37-cp37m-linux_x86_64.whl size=12877862 sha256=c12be0949a2fffa10422f78416544c09ebced68009f7879eac4884469c741f8a\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-iqkyrm0h/wheels/c3/6c/94/7d57d4f20a87a22ef1722eaad22052b4c435892b55400e5f4e\n",
            "Successfully built ctcdecode\n",
            "Installing collected packages: ctcdecode\n",
            "Successfully installed ctcdecode-1.0.2\n",
            "Collecting python-Levenshtein\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/dc/97f2b63ef0fa1fd78dcb7195aca577804f6b2b51e712516cc0e902a9a201/python-Levenshtein-0.12.2.tar.gz (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 3.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from python-Levenshtein) (54.2.0)\n",
            "Building wheels for collected packages: python-Levenshtein\n",
            "  Building wheel for python-Levenshtein (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-Levenshtein: filename=python_Levenshtein-0.12.2-cp37-cp37m-linux_x86_64.whl size=149801 sha256=054f57e79973705067cfbe6d9b25464fb161b527025e552d1363f3adbafa7029\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/26/73/4b48503bac73f01cf18e52cd250947049a7f339e940c5df8fc\n",
            "Successfully built python-Levenshtein\n",
            "Installing collected packages: python-Levenshtein\n",
            "Successfully installed python-Levenshtein-0.12.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc2u8W09FRB-"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1WcljITHEpo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5afddf00-6fc8-46d3-a0e9-e3617cefabe3"
      },
      "source": [
        "!pip install torchaudio"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchaudio\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/aa/55/01ad9244bcd595e39cea5ce30726a7fe02fd963d07daeb136bfe7e23f0a5/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9MB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (3.7.4.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (1.19.5)\n",
            "Installing collected packages: torchaudio\n",
            "Successfully installed torchaudio-0.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APVglqdY-JXD"
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import PIL\n",
        "import timeit\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torch.nn.utils.rnn import *\n",
        "import torchaudio\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from Levenshtein import distance as levenshtein_distance\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from datetime import datetime as dt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I2aD0rgdF5iq"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3V828I34-QCp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a535c06-6291-4cbf-8bd1-63ad99ced661"
      },
      "source": [
        "# Check if cuda is available\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "num_workers = 4 if cuda else 0\n",
        "print(\"Cuda = \"+str(cuda)+\" with num_workers = \"+str(num_workers))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda = True with num_workers = 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYsooncS-P_w"
      },
      "source": [
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = 'cuda:0'\n",
        "    else:\n",
        "        device = 'cpu'\n",
        "    return device\n",
        "device = get_device()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YAhJzG3ANT07"
      },
      "source": [
        "# DEEPSPEECH2"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9fwxwvv-JN7"
      },
      "source": [
        "class RnnDataset(Dataset):\n",
        "    def __init__(self, x_path, y_path, train=False):\n",
        "        self.train = train\n",
        "        self.X = np.load(x_path, allow_pickle=True)\n",
        "        self.y = np.load(y_path, allow_pickle=True)\n",
        "        print(self.X.shape, self.y.shape)\n",
        "\n",
        "        self.length = self.X.shape[0]\n",
        "\n",
        "        self.transforms = nn.Sequential(\n",
        "        torchaudio.transforms.FrequencyMasking(freq_mask_param=15),\n",
        "        torchaudio.transforms.TimeMasking(time_mask_param=35),\n",
        "        )\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.X[index]\n",
        "        y = self.y[index]\n",
        "\n",
        "        if self.train:\n",
        "            x = self.transforms(torch.LongTensor(x))\n",
        "\n",
        "        return x,y\n",
        "\n",
        "def rnn_collate(batch):\n",
        "    data = [torch.LongTensor(item[0]) for item in batch]\n",
        "    data_lengths = torch.LongTensor([len(seq) for seq in data])\n",
        "    data = pad_sequence(data)\n",
        "    \n",
        "    target = [torch.LongTensor(item[1]) for item in batch]\n",
        "    target_lengths = torch.LongTensor([len(seq) for seq in target])\n",
        "    target = pad_sequence(target, batch_first=True)\n",
        "\n",
        "    return [data, target, data_lengths, target_lengths]\n",
        "\n",
        "def pad_collate(batch):\n",
        "\n",
        "    data = [torch.LongTensor(item[0]) for item in batch]\n",
        "    data_lengths = torch.LongTensor([len(seq) for seq in data])\n",
        "    data = pad_sequence(data)\n",
        "    \n",
        "    max_seqlength = data.shape[0]\n",
        "    input_len_ratio = torch.FloatTensor([item[0].shape[0]/float(max_seqlength) for item in batch])\n",
        "\n",
        "    target = [torch.LongTensor(item[1]) for item in batch]\n",
        "    target_lengths = torch.LongTensor([len(seq) for seq in target])\n",
        "    target = pad_sequence(target, batch_first=True)\n",
        "\n",
        "    return data, target, data_lengths, target_lengths, input_len_ratio"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iz-zU2qpX9_8"
      },
      "source": [
        ""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tFxgoggJCXL"
      },
      "source": [
        "batch_size = 128"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhEY0s3EKq1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93ebc234-bdca-4a56-c080-fe6342d7fcec"
      },
      "source": [
        "## Dataloaders\n",
        "\n",
        "# # Training dataloader\n",
        "train_data = RnnDataset(train_filename, train_labels_filename, train=True)\n",
        "train_args = dict(shuffle = True, batch_size = batch_size, num_workers=num_workers, drop_last=True, collate_fn=pad_collate)\n",
        "train_loader = DataLoader(train_data, **train_args)\n",
        "\n",
        "# # Validation dataloader\n",
        "val_data = RnnDataset(dev_filename, dev_labels_filename, train=False)\n",
        "val_args = dict(shuffle = True, batch_size = batch_size, num_workers=num_workers, drop_last=True, collate_fn=pad_collate)\n",
        "val_loader = DataLoader(val_data, **val_args)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(14542,) (14542,)\n",
            "(2200,) (2200,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nrMhP1FKay9"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5TFF3L2iLRv"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout(p=0.2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class Wav2Letter(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes, num_features = 40):\n",
        "        super(Wav2Letter, self).__init__()\n",
        "\n",
        "        model = nn.Sequential(\n",
        "            ConvBlock(in_channels=num_features, out_channels=250, kernel_size=48, stride=2, padding=23),\n",
        "\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "\n",
        "            ConvBlock(in_channels=250, out_channels=2000, kernel_size=32, stride=1, padding=16),\n",
        "            ConvBlock(in_channels=2000, out_channels=2000, kernel_size=1, stride=1, padding=0),\n",
        "            nn.Conv1d(in_channels=2000, out_channels=num_classes, kernel_size=1, stride=1, padding=0)\n",
        "        )\n",
        "        \n",
        "        self.model = model\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Input - (batch_size, num_features, input_length)\n",
        "        out = self.model(x)\n",
        "        out = self.log_softmax(out)\n",
        "        \n",
        "        return out.transpose(0,1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyXN3_wDrjWq"
      },
      "source": [
        "epochs = 250\n",
        "learning_rate = 2e-3\n",
        "max_lr = 5e-3\n",
        "num_features = 40\n",
        "hidden_dim = 512\n",
        "out_vocab = N_PHONEMES+1\n",
        "gamma = 0.95\n",
        "weight_decay = 5e-5"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMTq4Sdxqnnd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce6cda7-6529-4d40-8669-402038dd3a67"
      },
      "source": [
        "model = Wav2Letter(out_vocab)\n",
        "model.to(device)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Wav2Letter(\n",
              "  (model): Sequential(\n",
              "    (0): ConvBlock(\n",
              "      (conv): Conv1d(40, 250, kernel_size=(48,), stride=(2,), padding=(23,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (1): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (2): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (3): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (4): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (5): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (6): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (7): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (8): ConvBlock(\n",
              "      (conv): Conv1d(250, 2000, kernel_size=(32,), stride=(1,), padding=(16,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (9): ConvBlock(\n",
              "      (conv): Conv1d(2000, 2000, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "      (dropout): Dropout(p=0.2, inplace=False)\n",
              "    )\n",
              "    (10): Conv1d(2000, 42, kernel_size=(1,), stride=(1,))\n",
              "  )\n",
              "  (log_softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ka7a3aZMOvb"
      },
      "source": [
        "torch.manual_seed(0)\n",
        "criterion = nn.CTCLoss().to(device)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=max_lr, steps_per_epoch=len(train_loader), epochs=epochs, anneal_strategy='linear')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3recbi5fbSW"
      },
      "source": [
        ""
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDiCY0aEA84Z"
      },
      "source": [
        "def calc_levenshtein_dist(list1, list2):\n",
        "\n",
        "    dist = 0\n",
        "    for index in range(len(list1)):\n",
        "        dist += levenshtein_distance(list1[index], list2[index])\n",
        "\n",
        "    return dist/len(list1)\n",
        "\n",
        "def unpad(padded_seq, lengths):\n",
        "    unpadded_list = []\n",
        "    for index in range(padded_seq.shape[0]):\n",
        "      unpadded_list.append(padded_seq[index][0][:lengths[index][0]])\n",
        "    \n",
        "    return unpadded_list\n",
        "\n",
        "def unpad_beam1(padded_seq, lengths):\n",
        "    unpadded_list = []\n",
        "    for index in range(len(lengths)):\n",
        "      unpadded_list.append(padded_seq[index, :lengths[index]])\n",
        "    \n",
        "    return unpadded_list"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Iblky2_6dHD"
      },
      "source": [
        "def generate_output(class_labels):\n",
        "    out_string = \"\"\n",
        "    for label in class_labels:\n",
        "      if label == 0:\n",
        "        continue\n",
        "      else:\n",
        "        out_string += PHONEME_MAP[label]\n",
        "    return out_string\n",
        "\n",
        "def generate_all_outputs(labels_all):\n",
        "  \n",
        "    output_strings = []\n",
        "    for batch in labels_all:\n",
        "        for class_labels in batch:\n",
        "            output_strings.append(generate_output(class_labels))\n",
        "    \n",
        "    return output_strings"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we6mKPpUVb47"
      },
      "source": [
        ""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLlT9Q2CVXTG"
      },
      "source": [
        "# Train the model\n",
        "\n",
        "def train_model(train_loader, model):\n",
        "    training_loss = 0\n",
        "    \n",
        "    # Set model in 'Training mode'\n",
        "    model.train()\n",
        "    \n",
        "    # enumerate mini batches\n",
        "    for i, (inputs, targets, input_lengths, target_lengths, input_len_ratio) in enumerate(train_loader):\n",
        "\n",
        "        inputs = inputs.transpose(0,1).transpose(1,2).reshape((batch_size, 40, -1)).to(device)\n",
        "        input_lengths = input_lengths.to(device)\n",
        "        targets = targets.to(device)\n",
        "        target_lengths = target_lengths.to(device)\n",
        "        \n",
        "        # clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # compute the model output\n",
        "        out = model(inputs.float())\n",
        "        out = out.permute(2,1,0)\n",
        "\n",
        "        seq_length = out.size(0)\n",
        "        out_lengths = Variable(input_len_ratio.mul_(int(seq_length)).int(), requires_grad=False)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = criterion(out, targets, out_lengths, target_lengths)\n",
        "        \n",
        "        del out\n",
        "        del out_lengths\n",
        "        del targets\n",
        "        del target_lengths\n",
        "        del inputs\n",
        "        del input_lengths\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update model weights\n",
        "        optimizer.step()\n",
        "\n",
        "        training_loss += loss.item()\n",
        "    training_loss /= len(train_loader)\n",
        "    return training_loss"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M26w2hFWpMrJ"
      },
      "source": [
        "# Evaluate the model\n",
        "\n",
        "def evaluate_model(val_loader, model):\n",
        "    \n",
        "    predictions = []\n",
        "    actuals = []\n",
        "\n",
        "    distances = []\n",
        "\n",
        "    # Set model in validation mode\n",
        "    model.eval()\n",
        "\n",
        "    for i, (inputs, targets, input_lengths, target_lengths, input_len_ratio) in enumerate(val_loader):\n",
        "\n",
        "        inputs = inputs.transpose(0,1).transpose(1,2).reshape((batch_size, 40, -1)).to(device)\n",
        "        input_lengths = input_lengths.to(device)\n",
        "        targets = targets.to(device)\n",
        "        target_lengths = target_lengths.to(device)\n",
        "\n",
        "        # evaluate the model on the validation set\n",
        "        out = model(inputs.float())\n",
        "        out = out.permute(2,1,0)\n",
        "\n",
        "        seq_length = out.size(0)\n",
        "        out_lengths = Variable(input_len_ratio.mul_(int(seq_length)).int(), requires_grad=False)\n",
        "                \n",
        "        # Calculate validation loss\n",
        "        loss = criterion(out, targets, out_lengths, target_lengths)\n",
        "\n",
        "        actual = targets.cpu().numpy()\n",
        "        actual_lengths = target_lengths.cpu().numpy()\n",
        "\n",
        "        decoder = CTCBeamDecoder(PHONEME_MAP, beam_width=4, log_probs_input=True)\n",
        "        out, _, _, out_lengths = decoder.decode(out.transpose(0, 1), out_lengths)\n",
        " \n",
        "    ## reshape for stacking\n",
        "        actual = unpad_beam1(actual, actual_lengths)\n",
        "        out = unpad(torch.squeeze(out, 1).cpu().numpy(), torch.squeeze(out_lengths, 1).cpu().numpy())\n",
        "    \n",
        "    ## store\n",
        "        predictions.append(out)\n",
        "        actuals.append(actual)\n",
        "\n",
        "        del out\n",
        "        del out_lengths\n",
        "        del targets\n",
        "        del target_lengths\n",
        "        del inputs\n",
        "        del input_lengths\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    p = generate_all_outputs(predictions)\n",
        "    a = generate_all_outputs(actuals)\n",
        "\n",
        "    ## Calculate Validation Levenshtein distance\n",
        "    if len(p) != len(a):\n",
        "        print(\"ERROR\")\n",
        "\n",
        "    dist = calc_levenshtein_dist(a, p)\n",
        "    \n",
        "    return dist, loss.item()\n",
        "    "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4H0Whi9lVtbO"
      },
      "source": [
        ""
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XoyqMs_zADWB"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    print(\"Epoch: \", epoch)\n",
        "\n",
        "    if epoch % 10 == 0 and epoch != 0:\n",
        "      torch.save(model, MODEL_PATH + \"wav2letter_init_epoch.pth\")\n",
        "\n",
        "    # Train\n",
        "    starttime = timeit.default_timer()\n",
        "    training_loss = train_model(train_loader, model)\n",
        "    endtime = timeit.default_timer()\n",
        "    print(\"Training time: \", (endtime - starttime)/60)\n",
        "\n",
        "    # Validation\n",
        "    starttime = timeit.default_timer()\n",
        "    \n",
        "    val_dist, val_loss = evaluate_model(val_loader, model)\n",
        "    endtime = timeit.default_timer()\n",
        "    print(\"Validation time: \", (endtime - starttime)/60)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "    lr_print = scheduler.get_last_lr()\n",
        "\n",
        "    # Print log of accuracy and loss\n",
        "    print(\"Epoch: \"+str(epoch)+\", Training loss: \"+str(training_loss)+\", Validation loss: \"+str(val_loss)+\n",
        "          \", Validation distance: \"+str(val_dist)+\", LR: \"+str(lr_print)+\"\\n\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx2f828yElOF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6akBwhD2FoC"
      },
      "source": [
        "time_now = dt.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "model_name = \"5l_dropout_da\" + time_now\n",
        "model_filename = MODEL_PATH + model_name + \".pth\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXAQWLx9HFVY"
      },
      "source": [
        "torch.save(model, model_filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8gMq5ARChYQ"
      },
      "source": [
        "# Test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLjY3LX1ChVJ"
      },
      "source": [
        "class RnnTestDataset(Dataset):\n",
        "    def __init__(self, x_path):\n",
        "        self.X = np.load(x_path, allow_pickle=True)\n",
        "        print(self.X.shape)\n",
        "\n",
        "        self.length = self.X.shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.X[index]\n",
        "\n",
        "        return x\n",
        "\n",
        "def rnn_collate_test(batch):\n",
        "    data = [torch.LongTensor(item) for item in batch]\n",
        "    data_lengths = torch.LongTensor([len(seq) for seq in data])\n",
        "    data = pad_sequence(data)\n",
        "\n",
        "    return [data, data_lengths]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1qTulBtDQ7J"
      },
      "source": [
        "test_data = RnnTestDataset(test_filename)\n",
        "test_args = dict(shuffle = False, batch_size=batch_size, num_workers=num_workers, drop_last=False, collate_fn=rnn_collate_test)\n",
        "test_loader = DataLoader(test_data, **test_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSsRdcaKIiyU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3qmWmXLDsdF"
      },
      "source": [
        "# Evaluate the model\n",
        "\n",
        "def predict(test_loader, model):\n",
        "    \n",
        "    predictions = []\n",
        "\n",
        "    # Set model in validation mode\n",
        "    model.eval()\n",
        "\n",
        "    for i, (inputs, input_lengths) in enumerate(test_loader):\n",
        "        # print(inputs.shape)\n",
        "\n",
        "        inputs = inputs.transpose(0,1).transpose(1,2).reshape((inputs.shape[1], 1, 40, -1)).to(device)\n",
        "        input_lengths = input_lengths.to(device)\n",
        "\n",
        "        # evaluate the model on the validation set\n",
        "        out, out_lengths = model(inputs.float(), input_lengths)\n",
        "        decoder = CTCBeamDecoder(PHONEME_MAP, beam_width=10, log_probs_input=True)\n",
        "        out, _, _, out_lengths = decoder.decode(out.transpose(0, 1), out_lengths)\n",
        "\n",
        "    ## reshape for stacking and store\n",
        "        out = torch.squeeze(out, 1).cpu().numpy()\n",
        "        out_lengths = torch.squeeze(out_lengths, 1).cpu().numpy()\n",
        "\n",
        "        out = unpad(out, out_lengths)\n",
        "        predictions.append(out)\n",
        "    \n",
        "    pred_labels = generate_all_outputs(predictions)\n",
        "    \n",
        "    return pred_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTxxeMhXDQ4I"
      },
      "source": [
        "pred_labels = predict(test_loader, model)\n",
        "id_vals = list(range(len(pred_labels)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iP45FnkMVhn"
      },
      "source": [
        "len(pred_labels) == 2561"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JC-lua2WMVdy"
      },
      "source": [
        "submission_dict = {\"id\":id_vals, \"label\":pred_labels}\n",
        "submission = pd.DataFrame(submission_dict)\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nk2xqBIMMVYJ"
      },
      "source": [
        "len(submission)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA2kAepPMVRy"
      },
      "source": [
        "submission.to_csv(PREDICTION_PATH + model_name + \"beam10.csv\", header=True, index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbvGi4h1IO5x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}