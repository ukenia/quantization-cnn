{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wav2Letter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ukenia/quantization-cnn/blob/starter-code/Wav2Letter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7qqYlbva-11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10a7c507-9e5b-4dac-a924-1c819ce0bfaa"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Apr  8 15:46:24 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   62C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37Nhb2J5f1l2"
      },
      "source": [
        "# !pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_o_w4fmf4dX"
      },
      "source": [
        "import sentencepiece as spm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn8ym7OShZwg"
      },
      "source": [
        ""
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE36AA_eKlfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5830d74-e563-4756-ae1d-fe74975160cc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gu1rUqsFhggQ"
      },
      "source": [
        "# spm.SentencePieceTrainer.train('--input=/content/gdrive/MyDrive/idl_proj/data/train_transcripts.npy --model_prefix=train_model --vocab_size=200 --character_coverage=1.0 --model_type=char')\n",
        "\n",
        "# makes segmenter instance and loads the model file (m.model)\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('train_model.model')\n",
        "label_map = [sp.id_to_piece(id) for id in range(sp.get_piece_size())]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mT1CJ3wUhsbQ",
        "outputId": "3243d481-8841-4973-bfbd-ed08fc80c915",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "sp.encode_as_ids('This is a test')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[30, 64, 6, 11, 12, 30, 11, 12, 30, 8, 30, 5, 3, 12, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IV9PursiXjW",
        "outputId": "ef7eaccd-71a3-48a0-80d8-ef3260ded472",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(sp.get_piece_size())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "200\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3gEox1ohktw",
        "outputId": "278ad313-ad30-4301-ce42-40aa77ae3b47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "sp.id_to_piece(50)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'&'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpbl5j8PrmMm"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34WOZoSLKlcU"
      },
      "source": [
        "BASE_PATH = \"/content/gdrive/MyDrive/idl_proj/\"\n",
        "DATA_PATH = BASE_PATH + \"data/\"\n",
        "MODEL_PATH = BASE_PATH + \"models/\"\n",
        "PREDICTION_PATH = BASE_PATH + \"predictions/\""
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BolL8-n8KlZZ"
      },
      "source": [
        "# Files from drive\n",
        "train_filename = DATA_PATH + \"train.npy\"\n",
        "train_transcripts_filename = DATA_PATH + \"train_transcripts.npy\"\n",
        "\n",
        "dev_filename = DATA_PATH + \"dev.npy\"\n",
        "dev_transcripts_filename = DATA_PATH + \"dev_transcripts.npy\"\n",
        "\n",
        "test_filename = DATA_PATH + \"test.npy\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV9iOmhzKlWx"
      },
      "source": [
        "# # Installing CTC Decoder\n",
        "# !git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "# !cd ctcdecode && pip install ."
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DupCkR4LK2J8"
      },
      "source": [
        "# Code starts here!"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "503jxBw-K2Fp"
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import timeit\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import *\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "from datetime import datetime as dt"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0byjchEK_Hb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdcbf3f6-1456-4f1f-bdef-3f8779e9f1d0"
      },
      "source": [
        "# Check if cuda is available\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "num_workers = 4 if cuda else 0\n",
        "print(\"Cuda = \"+str(cuda)+\" with num_workers = \"+str(num_workers))\n",
        "\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = 'cuda:0'\n",
        "    else:\n",
        "        device = 'cpu'\n",
        "    return device\n",
        "device = get_device()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda = True with num_workers = 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUbB9PzWK_FH"
      },
      "source": [
        ""
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eezaZtfLEfN"
      },
      "source": [
        "class Wav2LetterDataset(Dataset):\n",
        "    def __init__(self, x_path, y_path):\n",
        "        self.X = np.load(x_path, allow_pickle=True)\n",
        "        self.y = np.load(y_path, allow_pickle=True)\n",
        "\n",
        "        self.length = self.X.shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.X[index]\n",
        "        y = b' '.join(self.y[index]).decode('utf-8')\n",
        "        y = sp.encode_as_ids(y)\n",
        "\n",
        "        return x, y\n",
        "\n",
        "def pad_collate(batch):\n",
        "\n",
        "    data = [torch.LongTensor(item[0]) for item in batch]\n",
        "    data_lengths = torch.LongTensor([len(seq) for seq in data])\n",
        "    data = pad_sequence(data)\n",
        "    \n",
        "    max_seqlength = data.shape[0]\n",
        "    input_len_ratio = torch.FloatTensor([item[0].shape[0]/float(max_seqlength) for item in batch])\n",
        "\n",
        "    target = [torch.LongTensor(item[1]) for item in batch]\n",
        "    target_lengths = torch.LongTensor([len(seq) for seq in target])\n",
        "    target = pad_sequence(target, batch_first=True)\n",
        "  \n",
        "    return data, target, data_lengths, target_lengths, input_len_ratio"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Ag9rsyMgzk"
      },
      "source": [
        "hyperparameters = {\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 5e-3,\n",
        "    \"weight_decay\": 1e-5,\n",
        "}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6b-6pauLEct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a37def-6721-4406-e84c-329868721e6f"
      },
      "source": [
        "train_data = Wav2LetterDataset(train_filename, train_transcripts_filename)\n",
        "train_args = dict(shuffle=True, batch_size=hyperparameters[\"batch_size\"], num_workers=num_workers, drop_last=True, collate_fn=pad_collate)\n",
        "train_loader = DataLoader(train_data, **train_args)\n",
        "\n",
        "val_data = Wav2LetterDataset(dev_filename, dev_transcripts_filename)\n",
        "val_args = dict(shuffle=True, batch_size=hyperparameters[\"batch_size\"], num_workers=num_workers, drop_last=True, collate_fn=pad_collate)\n",
        "val_loader = DataLoader(val_data, **val_args)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORXykcJ0cb_v"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMOYxZqdbgdi"
      },
      "source": [
        "class Wav2Letter(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes = 42, num_features = 40):\n",
        "        super(Wav2Letter, self).__init__()\n",
        "\n",
        "        model = nn.Sequential(\n",
        "            ConvBlock(in_channels=num_features, out_channels=250, kernel_size=48, stride=2, padding=23),\n",
        "\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "\n",
        "            ConvBlock(in_channels=250, out_channels=2000, kernel_size=32, stride=1, padding=16),\n",
        "            ConvBlock(in_channels=2000, out_channels=2000, kernel_size=1, stride=1, padding=0),\n",
        "            ConvBlock(in_channels=2000, out_channels=num_classes, kernel_size=1, stride=1, padding=0)\n",
        "        )\n",
        "        \n",
        "        self.model = model\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Input - (batch_size, num_features, input_length)\n",
        "        out = self.model(x)\n",
        "        out = self.log_softmax(out)\n",
        "        \n",
        "        return out.transpose(0,1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZne-30ERSZU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ecc260b-3b82-4d8f-8903-3b68275d3fb2"
      },
      "source": [
        "model = Wav2Letter()\n",
        "model.to(device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Wav2Letter(\n",
              "  (model): Sequential(\n",
              "    (0): ConvBlock(\n",
              "      (conv): Conv1d(40, 250, kernel_size=(48,), stride=(2,), padding=(23,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): ConvBlock(\n",
              "      (conv): Conv1d(250, 2000, kernel_size=(32,), stride=(1,), padding=(16,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): ConvBlock(\n",
              "      (conv): Conv1d(2000, 2000, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): ConvBlock(\n",
              "      (conv): Conv1d(2000, 42, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (log_softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmmoW_2pRSW4"
      },
      "source": [
        "criterion = nn.CTCLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameters[\"learning_rate\"], weight_decay=hyperparameters[\"weight_decay\"])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5) # OR can use some other scheduler"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLEQdoB5RS3E"
      },
      "source": [
        ""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54TrXFwJR7W9"
      },
      "source": [
        "# Train the model - Change based on the model\n",
        "\n",
        "def train_model(train_loader, model):\n",
        "    training_loss = 0\n",
        "    \n",
        "    # Set model in 'Training mode'\n",
        "    model.train()\n",
        "    \n",
        "    # enumerate mini batches\n",
        "    for i, (inputs, targets, input_lengths, target_lengths, input_len_ratio) in enumerate(train_loader):\n",
        "\n",
        "        inputs = inputs.transpose(0,1).transpose(1,2).reshape((hyperparameters[\"batch_size\"], 40, -1)).to(device)        \n",
        "        targets = targets.to(device)\n",
        "        \n",
        "        # clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # compute the model output\n",
        "        out = model(inputs.float())\n",
        "        \n",
        "        # calculate loss\n",
        "        seq_length = out.size(0)\n",
        "        out_lengths = Variable(input_len_ratio.mul_(int(seq_length)).int(), requires_grad=False)\n",
        "        loss = criterion(out, targets, out_lengths, target_lengths)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update model weights\n",
        "        optimizer.step()\n",
        "\n",
        "        training_loss += loss.item()\n",
        "    training_loss /= len(train_loader)\n",
        "    return training_loss"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH7ue4uDSH_K"
      },
      "source": [
        "# Evaluate the model - Change based on the model\n",
        "\n",
        "def evaluate_model(val_loader, model):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    # enumerate mini batches\n",
        "    for i, (inputs, targets, input_lengths, target_lengths, input_len_ratio) in enumerate(val_loader):\n",
        "\n",
        "        inputs = inputs.transpose(0,1).transpose(1,2).reshape((hyperparameters[\"batch_size\"], 40, -1)).to(device)        \n",
        "        targets = targets.to(device)\n",
        "        \n",
        "        # compute the model output\n",
        "        out = model(inputs.float())\n",
        "        \n",
        "        # calculate loss\n",
        "        seq_length = out.size(0)\n",
        "        out_lengths = Variable(input_len_ratio.mul_(int(seq_length)).int(), requires_grad=False)\n",
        "        loss = criterion(out, targets, out_lengths, target_lengths)\n",
        "\n",
        "        decoder = CTCBeamDecoder(label_map, beam_width=2, log_probs_input=True)\n",
        "        out, _, _, out_lengths = decoder.decode(out.transpose(0, 1), out_lengths)\n",
        "        \n",
        "\n",
        "    return loss.item()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrtKnsBrR7UM"
      },
      "source": [
        "for epoch in range(hyperparameters[\"epochs\"]):\n",
        "    print(\"Epoch: \", epoch)\n",
        "\n",
        "    if epoch % 10 == 0 and epoch != 0:\n",
        "      torch.save(model, MODEL_PATH + \"base_model.pth\")\n",
        "\n",
        "    # Train\n",
        "    starttime = timeit.default_timer()\n",
        "    training_loss = train_model(train_loader, model)\n",
        "    endtime = timeit.default_timer()\n",
        "    print(\"Training time: \", (endtime - starttime)/60)\n",
        "\n",
        "    # Validation\n",
        "    starttime = timeit.default_timer()\n",
        "    val_dist, val_loss = evaluate_model(val_loader, model)\n",
        "    endtime = timeit.default_timer()\n",
        "    print(\"Validation time: \", (endtime - starttime)/60)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Print log of accuracy and loss\n",
        "    print(\"Epoch: \"+str(epoch)+\", Training loss: \"+str(training_loss)+\", Validation loss: \"+str(val_loss)+\n",
        "          \", Validation distance: \"+str(val_dist)+\", LR: \"+str(scheduler.get_last_lr())+\"\\n\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJw_M-qJvH9s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}