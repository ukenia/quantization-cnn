{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wav2Letter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ukenia/quantization-cnn/blob/starter-code/Wav2Letter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7qqYlbva-11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f91333-54cf-473f-f9cb-b8369f41592d"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Apr  7 22:17:33 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE36AA_eKlfE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63270ba3-d977-4d6e-918c-ad142a79b4bf"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34WOZoSLKlcU"
      },
      "source": [
        "BASE_PATH = \"/content/gdrive/MyDrive/idl_proj/\"\n",
        "DATA_PATH = BASE_PATH + \"data/\"\n",
        "MODEL_PATH = BASE_PATH + \"models/\"\n",
        "PREDICTION_PATH = BASE_PATH + \"predictions/\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BolL8-n8KlZZ"
      },
      "source": [
        "# Files from drive\n",
        "train_filename = DATA_PATH + \"train.npy\"\n",
        "train_transcripts_filename = DATA_PATH + \"train_transcripts.npy\"\n",
        "\n",
        "dev_filename = DATA_PATH + \"dev.npy\"\n",
        "dev_transcripts_filename = DATA_PATH + \"dev_transcripts.npy\"\n",
        "\n",
        "test_filename = DATA_PATH + \"test.npy\""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV9iOmhzKlWx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6add8aa8-3a9f-47d0-f4f3-a2a66777cf76"
      },
      "source": [
        "# Installing CTC Decoder\n",
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!cd ctcdecode && pip install ."
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ctcdecode'...\n",
            "remote: Enumerating objects: 1063, done.\u001b[K\n",
            "remote: Total 1063 (delta 0), reused 0 (delta 0), pack-reused 1063\u001b[K\n",
            "Receiving objects: 100% (1063/1063), 759.71 KiB | 18.99 MiB/s, done.\n",
            "Resolving deltas: 100% (513/513), done.\n",
            "Submodule 'third_party/ThreadPool' (https://github.com/progschj/ThreadPool.git) registered for path 'third_party/ThreadPool'\n",
            "Submodule 'third_party/kenlm' (https://github.com/kpu/kenlm.git) registered for path 'third_party/kenlm'\n",
            "Cloning into '/content/ctcdecode/third_party/ThreadPool'...\n",
            "remote: Enumerating objects: 82, done.        \n",
            "remote: Total 82 (delta 0), reused 0 (delta 0), pack-reused 82        \n",
            "Cloning into '/content/ctcdecode/third_party/kenlm'...\n",
            "remote: Enumerating objects: 13687, done.        \n",
            "remote: Total 13687 (delta 0), reused 0 (delta 0), pack-reused 13687        \n",
            "Receiving objects: 100% (13687/13687), 5.46 MiB | 22.82 MiB/s, done.\n",
            "Resolving deltas: 100% (7880/7880), done.\n",
            "Submodule path 'third_party/ThreadPool': checked out '9a42ec1329f259a5f4881a291db1dcb8f2ad9040'\n",
            "Submodule path 'third_party/kenlm': checked out '35835f1ac4884126458ac89f9bf6dd9ccad561e0'\n",
            "Processing /content/ctcdecode\n",
            "Building wheels for collected packages: ctcdecode\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ctcdecode: filename=ctcdecode-1.0.2-cp37-cp37m-linux_x86_64.whl size=12873736 sha256=814fd3db2fd3077afc6d5f800c7442f30d47b927795a4d7b36c30187c03de8ea\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h426bgiv/wheels/c3/6c/94/7d57d4f20a87a22ef1722eaad22052b4c435892b55400e5f4e\n",
            "Successfully built ctcdecode\n",
            "Installing collected packages: ctcdecode\n",
            "Successfully installed ctcdecode-1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DupCkR4LK2J8"
      },
      "source": [
        "# Code starts here!"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "503jxBw-K2Fp"
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import timeit\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import *\n",
        "\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "from datetime import datetime as dt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0byjchEK_Hb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a12367-4cbd-426f-dfdd-a1f82ba2d430"
      },
      "source": [
        "# Check if cuda is available\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "num_workers = 4 if cuda else 0\n",
        "print(\"Cuda = \"+str(cuda)+\" with num_workers = \"+str(num_workers))\n",
        "\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = 'cuda:0'\n",
        "    else:\n",
        "        device = 'cpu'\n",
        "    return device\n",
        "device = get_device()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda = True with num_workers = 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUbB9PzWK_FH"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eezaZtfLEfN"
      },
      "source": [
        "class Wav2LetterDataset(Dataset):\n",
        "    def __init__(self, x_path, y_path):\n",
        "        self.X = np.load(x_path, allow_pickle=True)\n",
        "        self.y = np.load(y_path, allow_pickle=True)\n",
        "\n",
        "        self.length = self.X.shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.X[index]\n",
        "        y = self.y[index]\n",
        "\n",
        "        return x, y\n",
        "\n",
        "def pad_collate(batch):\n",
        "    data = [torch.LongTensor(item[0]) for item in batch]\n",
        "    data_lengths = torch.LongTensor([len(seq) for seq in data])\n",
        "    data = pad_sequence(data)\n",
        "  \n",
        "    target = [torch.LongTensor(item[1]) for item in batch]\n",
        "    target_lengths = torch.LongTensor([len(seq) for seq in target])\n",
        "    target = pad_sequence(target, batch_first=True)\n",
        "  \n",
        "    return data, target, data_lengths, target_lengths"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Ag9rsyMgzk"
      },
      "source": [
        "hyperparameters = {\n",
        "    \"batch_size\": 32,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 5e-3,\n",
        "    \"weight_decay\": 1e-5,\n",
        "}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6b-6pauLEct"
      },
      "source": [
        "train_data = Wav2LetterDataset(train_filename, train_transcripts_filename)\n",
        "train_args = dict(shuffle=True, batch_size=hyperparameters[\"batch_size\"], num_workers=num_workers, drop_last=True, collate_fn=pad_collate)\n",
        "train_loader = DataLoader(train_data, **train_args)\n",
        "\n",
        "val_data = Wav2LetterDataset(dev_filename, dev_transcripts_filename)\n",
        "val_args = dict(shuffle=True, batch_size=hyperparameters[\"batch_size\"], num_workers=num_workers, drop_last=True, collate_fn=pad_collate)\n",
        "val_loader = DataLoader(val_data, **val_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORXykcJ0cb_v"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv1d(in_channels=acoustic_num_features, out_channels=250, kernel_size=48, stride=2, padding=23),\n",
        "        self. relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMOYxZqdbgdi"
      },
      "source": [
        "class Wav2Letter(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes = 42, num_features = 40):\n",
        "        super(Wav2Letter, self).__init__()\n",
        "\n",
        "        model = nn.Sequential(\n",
        "            ConvBlock(in_channels=num_features, out_channels=250, kernel_size=48, stride=2, padding=23)\n",
        "\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "\n",
        "            ConvBlock(in_channels=250, out_channels=2000, kernel_size=32, stride=1, padding=16),\n",
        "            ConvBlock(in_channels=2000, out_channels=2000, kernel_size=1, stride=1, padding=0),\n",
        "            ConvBlock(in_channels=2000, out_channels=num_classes, kernel_size=1, stride=1, padding=0)\n",
        "        )\n",
        "        \n",
        "        self.model = model\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Input - (batch_size, num_features, input_length)\n",
        "        out = self.model(x)\n",
        "        out = self.log_softmax(out)\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZne-30ERSZU"
      },
      "source": [
        "model = Wav2LetterModel()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmmoW_2pRSW4"
      },
      "source": [
        "criterion = nn.CTCLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameters[\"learning_rate\"], weight_decay=hyperparameters[\"weight_decay\"])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5) # OR can use some other scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLEQdoB5RS3E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54TrXFwJR7W9"
      },
      "source": [
        "# Train the model - Change based on the model\n",
        "\n",
        "def train_model(train_loader, model):\n",
        "    training_loss = 0\n",
        "    \n",
        "    # Set model in 'Training mode'\n",
        "    model.train()\n",
        "    \n",
        "    # enumerate mini batches\n",
        "    for i, (inputs, targets, input_lengths, target_lengths) in enumerate(train_loader):\n",
        "\n",
        "        inputs = inputs.transpose(0,1).transpose(1,2).reshape((batch_size, 1, 40, -1)).to(device)        \n",
        "        targets = targets.to(device)\n",
        "        \n",
        "        # clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # compute the model output\n",
        "        out = model(inputs.float())\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = criterion(out, targets)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update model weights\n",
        "        optimizer.step()\n",
        "\n",
        "        training_loss += loss.item()\n",
        "    training_loss /= len(train_loader)\n",
        "    return training_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH7ue4uDSH_K"
      },
      "source": [
        "# Evaluate the model - Change based on the model\n",
        "\n",
        "def evaluate_model(val_loader, model):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    # enumerate mini batches\n",
        "    for i, (inputs, targets, input_lengths, target_lengths) in enumerate(val_loader):\n",
        "\n",
        "        inputs = inputs.transpose(0,1).transpose(1,2).reshape((batch_size, 1, 40, -1)).to(device)        \n",
        "        targets = targets.to(device)\n",
        "        \n",
        "        # compute the model output\n",
        "        out = model(inputs.float())\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = criterion(out, targets)\n",
        "\n",
        "        decoder = CTCBeamDecoder(label_map, beam_width=4, log_probs_input=True)\n",
        "        out, _, _, out_lengths = decoder.decode(out.transpose(0, 1), out_lengths)\n",
        "        \n",
        "\n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrtKnsBrR7UM"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    print(\"Epoch: \", epoch)\n",
        "\n",
        "    if epoch % 10 == 0 and epoch != 0:\n",
        "      torch.save(model, MODEL_PATH + \"base_model.pth\")\n",
        "\n",
        "    # Train\n",
        "    starttime = timeit.default_timer()\n",
        "    training_loss = train_model(train_loader, model)\n",
        "    endtime = timeit.default_timer()\n",
        "    print(\"Training time: \", (endtime - starttime)/60)\n",
        "\n",
        "    # Validation\n",
        "    starttime = timeit.default_timer()\n",
        "    val_dist, val_loss = evaluate_model(val_loader, model)\n",
        "    endtime = timeit.default_timer()\n",
        "    print(\"Validation time: \", (endtime - starttime)/60)\n",
        "\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Print log of accuracy and loss\n",
        "    print(\"Epoch: \"+str(epoch)+\", Training loss: \"+str(training_loss)+\", Validation loss: \"+str(val_loss)+\n",
        "          \", Validation distance: \"+str(val_dist)+\", LR: \"+str(scheduler.get_last_lr())+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Le4sVRoTkrO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}