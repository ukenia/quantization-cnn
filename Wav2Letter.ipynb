{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wav2Letter.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ukenia/quantization-cnn/blob/starter-code/Wav2Letter.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t7qqYlbva-11"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yE36AA_eKlfE"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34WOZoSLKlcU"
      },
      "source": [
        "BASE_PATH = \"/content/gdrive/MyDrive/idl_project/\"\n",
        "DATA_PATH = BASE_PATH + \"data/\"\n",
        "MODEL_PATH = BASE_PATH + \"models/\"\n",
        "PREDICTION_PATH = BASE_PATH + \"predictions/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BolL8-n8KlZZ"
      },
      "source": [
        "# Files from drive\n",
        "train_filename = DATA_PATH + \"train.npy\"\n",
        "train_transcripts_filename = DATA_PATH + \"train_transcripts.npy\"\n",
        "\n",
        "dev_filename = DATA_PATH + \"dev.npy\"\n",
        "dev_transcripts_filename = DATA_PATH + \"dev_transcripts.npy\"\n",
        "\n",
        "test_filename = DATA_PATH + \"test.npy\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wb58WRfHa0n_",
        "outputId": "32daadba-9bbd-4356-b4a7-3c6a40975b2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install torchaudio"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from torchaudio) (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->torchaudio) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2t5XbjFZa42W"
      },
      "source": [
        "import torchaudio"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV9iOmhzKlWx"
      },
      "source": [
        "# Installing CTC Decoder\n",
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!cd ctcdecode && pip install ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DupCkR4LK2J8"
      },
      "source": [
        "# Code starts here!"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "503jxBw-K2Fp"
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import timeit\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import *\n",
        "\n",
        "# from ctcdecode import CTCBeamDecoder\n",
        "from datetime import datetime as dt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0byjchEK_Hb",
        "outputId": "83754f57-4317-41b7-ddff-b0afbfd2d1cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Check if cuda is available\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "num_workers = 4 if cuda else 0\n",
        "print(\"Cuda = \"+str(cuda)+\" with num_workers = \"+str(num_workers))\n",
        "\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = 'cuda:0'\n",
        "    else:\n",
        "        device = 'cpu'\n",
        "    return device\n",
        "device = get_device()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda = False with num_workers = 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNXjwnyeaj8Q",
        "outputId": "eb584bb5-121d-4303-ecf8-cc1178490342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "source": [
        "# model = torchaudio.models.Wav2Letter()\n",
        "# print(model)\n",
        "\n",
        "torchaudio.models"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-99741ba6d917>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# print(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: module 'torchaudio' has no attribute 'models'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUbB9PzWK_FH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eezaZtfLEfN"
      },
      "source": [
        "class Wav2LetterDataset(Dataset):\n",
        "    def __init__(self, x_path, y_path):\n",
        "        self.X = np.load(x_path, allow_pickle=True)\n",
        "        self.y = np.load(y_path, allow_pickle=True)\n",
        "\n",
        "        self.length = self.X.shape[0]\n",
        "\n",
        "     def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.X[index]\n",
        "        y = self.y[index]\n",
        "\n",
        "        return x, y\n",
        "\n",
        "def pad_collate():\n",
        "  # Need to pad based on the model for Wav2Letter\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0Ag9rsyMgzk"
      },
      "source": [
        "hyperparameters = {\n",
        "    \"batch_size\": 32\n",
        "    \"epochs\": 50\n",
        "    \"learning_rate\": 5e-3\n",
        "    \"weight_decay\": 1e-5\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a6b-6pauLEct"
      },
      "source": [
        "train_data = RnnDataset(train_filename, train_labels_filename)\n",
        "train_args = dict(shuffle=True, batch_size=hyperparameters[\"batch_size\"], num_workers=num_workers, drop_last=True, collate_fn=pad_collate)\n",
        "train_loader = DataLoader(train_data, **train_args)\n",
        "\n",
        "val_data = RnnDataset(dev_filename, dev_labels_filename)\n",
        "val_args = dict(shuffle=True, batch_size=hyperparameters[\"batch_size\"], num_workers=num_workers, drop_last=True, collate_fn=pad_collate)\n",
        "val_loader = DataLoader(val_data, **val_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORXykcJ0cb_v"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv1d(in_channels=acoustic_num_features, out_channels=250, kernel_size=48, stride=2, padding=23),\n",
        "        self. relu = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMOYxZqdbgdi"
      },
      "source": [
        "class Wav2Letter(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes = 42, num_features = 40):\n",
        "        super(Wav2Letter, self).__init__()\n",
        "\n",
        "        model = nn.Sequential(\n",
        "            ConvBlock(in_channels=num_features, out_channels=250, kernel_size=48, stride=2, padding=23)\n",
        "\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "\n",
        "            ConvBlock(in_channels=250, out_channels=2000, kernel_size=32, stride=1, padding=16),\n",
        "            ConvBlock(in_channels=2000, out_channels=2000, kernel_size=1, stride=1, padding=0),\n",
        "            ConvBlock(in_channels=2000, out_channels=num_classes, kernel_size=1, stride=1, padding=0)\n",
        "        )\n",
        "        \n",
        "        self.model = model\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Input - (batch_size, num_features, input_length)\n",
        "        out = self.model(x)\n",
        "        out = self.log_softmax(out)\n",
        "        return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZne-30ERSZU"
      },
      "source": [
        "model = Wav2LetterModel()\n",
        "model.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmmoW_2pRSW4"
      },
      "source": [
        "criterion = nn.CTCLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameters[\"learning_rate\"], weight_decay=hyperparameters[\"weight_decay\"])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5) # OR can use some other scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLEQdoB5RS3E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54TrXFwJR7W9"
      },
      "source": [
        "# Train the model - Change based on the model\n",
        "\n",
        "def train_model(train_loader, model):\n",
        "    training_loss = 0\n",
        "    \n",
        "    # Set model in 'Training mode'\n",
        "    model.train()\n",
        "    \n",
        "    # enumerate mini batches\n",
        "    for i, (inputs, targets) in enumerate(train_loader):\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        \n",
        "        # clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # compute the model output\n",
        "        out = model(inputs.float())\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = criterion(out, targets)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update model weights\n",
        "        optimizer.step()\n",
        "\n",
        "        training_loss += loss.item()\n",
        "    training_loss /= len(train_loader)\n",
        "    return training_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH7ue4uDSH_K"
      },
      "source": [
        "# Evaluate the model - Change based on the model\n",
        "\n",
        "def evaluate_model(val_loader, model):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    # enumerate mini batches\n",
        "    for i, (inputs, targets) in enumerate(train_loader):\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "        \n",
        "        # compute the model output\n",
        "        out = model(inputs.float())\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = criterion(out, targets)\n",
        "        \n",
        "\n",
        "    return loss.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrtKnsBrR7UM"
      },
      "source": [
        "for epoch in range(epochs):\n",
        "    print(\"Epoch: \", epoch)\n",
        "\n",
        "    if epoch % 10 == 0 and epoch != 0:\n",
        "      torch.save(model, MODEL_PATH + \"base_model.pth\")\n",
        "\n",
        "    # Train\n",
        "    starttime = timeit.default_timer()\n",
        "    training_loss = train_model(train_loader, model)\n",
        "    endtime = timeit.default_timer()\n",
        "    print(\"Training time: \", (endtime - starttime)/60)\n",
        "\n",
        "    # Validation\n",
        "    starttime = timeit.default_timer()\n",
        "    val_dist, val_loss = evaluate_model(val_loader, model)\n",
        "    endtime = timeit.default_timer()\n",
        "    print(\"Validation time: \", (endtime - starttime)/60)\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    # Print log of accuracy and loss\n",
        "    print(\"Epoch: \"+str(epoch)+\", Training loss: \"+str(training_loss)+\", Validation loss: \"+str(val_loss)+\n",
        "          \", Validation distance: \"+str(val_dist)+\", LR: \"+str(scheduler.get_last_lr())+\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Le4sVRoTkrO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}