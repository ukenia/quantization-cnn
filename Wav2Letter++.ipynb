{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wav2Letter++.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPvpCFqtJ3MN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "65bacbe7-fe61-43cc-d3f4-8381fd9a9ace"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr  9 05:30:22 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P8    12W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlQiXTwKi5am",
        "outputId": "dfb6339c-6893-4425-98fe-49cffa0d849b"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncrjElbMiwrC"
      },
      "source": [
        "import sentencepiece as spm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwp1-zBii3a-",
        "outputId": "d957fc55-783c-4e65-f9f6-e9b08bd2fe7f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi5f903ySZw0",
        "outputId": "6b5ab142-d0e8-4909-ee68-13340d75d585"
      },
      "source": [
        "ls gdrive/MyDrive/idl_proj/data"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.npy                      test.npy        train_std2.npy\n",
            "dev.npy.zip                  test.npy.zip    train_std.npy\n",
            "dev_transcripts_cleaned.txt  train_mean.npy  train_transcripts_cleaned_mini.txt\n",
            "dev_transcripts.npy          train_mini.npy  train_transcripts_cleaned.txt\n",
            "sample.csv                   train.npy       train_transcripts.npy\n",
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/                 train.npy.zip   train_transcripts.npy.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "macsrPxci9Nm",
        "outputId": "07efc216-93e5-46ad-c015-65aeb3705aea"
      },
      "source": [
        "cd /content/gdrive/MyDrive/idl_proj/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/idl_proj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_gn_oz2jD8k",
        "outputId": "32af6ea9-c5cd-4c40-c132-b296fad22ff6"
      },
      "source": [
        "ls data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.npy                      test.npy        train_std2.npy\n",
            "dev.npy.zip                  test.npy.zip    train_std.npy\n",
            "dev_transcripts_cleaned.txt  train_mean.npy  train_transcripts_cleaned_mini.txt\n",
            "dev_transcripts.npy          train_mini.npy  train_transcripts_cleaned.txt\n",
            "sample.csv                   train.npy       train_transcripts.npy\n",
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/                 train.npy.zip   train_transcripts.npy.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exk3MZ-WjNug"
      },
      "source": [
        "import os"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSolDD2NjHZf"
      },
      "source": [
        "BASE_PATH = \"/content/gdrive/MyDrive/idl_proj/\"\n",
        "DATA_PATH = os.path.join(BASE_PATH, \"data\")\n",
        "MODEL_PATH = os.path.join(BASE_PATH, \"models\")\n",
        "PREDICTION_PATH = os.path.join(BASE_PATH, \"predictions\")"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aoiq_uQLjOk4",
        "outputId": "50923cbe-e8e9-4135-83a9-1da94a50a23e"
      },
      "source": [
        "# # Installing CTC Decoder\n",
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!cd ctcdecode && pip install ."
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'ctcdecode' already exists and is not an empty directory.\n",
            "Processing /content/gdrive/MyDrive/idl_proj/ctcdecode\n",
            "Building wheels for collected packages: ctcdecode\n",
            "  Building wheel for ctcdecode (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ctcdecode: filename=ctcdecode-1.0.2-cp37-cp37m-linux_x86_64.whl size=12877755 sha256=fed33c3c05ccdcdf5193ebee6c04e9e50309ade343dd723f2e1213f6790bb00e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-rot7ht0j/wheels/2b/33/31/5d0b9670a4ad51535fe162448223c80b2bf1cbb17ee4793b3c\n",
            "Successfully built ctcdecode\n",
            "Installing collected packages: ctcdecode\n",
            "Successfully installed ctcdecode-1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOC0fRfNkzjG"
      },
      "source": [
        "import time"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAynC33HjRfZ"
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import timeit\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import *\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "from datetime import datetime as dt"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW6KLLbfjX6K",
        "outputId": "cc2d189a-5ecf-4d3b-d844-f31ccfe3c2b8"
      },
      "source": [
        "# Check if cuda is available\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "num_workers = 4 if cuda else 0\n",
        "print(\"Cuda = \"+str(cuda)+\" with num_workers = \"+str(num_workers))\n",
        "\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = 'cuda:0'\n",
        "    else:\n",
        "        device = 'cpu'\n",
        "    return device\n",
        "device = get_device()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda = True with num_workers = 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqiJfle3kfAE"
      },
      "source": [
        "# Files from drive\n",
        "train_filename = os.path.join(DATA_PATH, 'train_mini.npy')\n",
        "train_transcripts_filename = os.path.join(DATA_PATH, 'train_transcripts_cleaned_mini.txt')\n",
        "\n",
        "dev_filename = os.path.join(DATA_PATH, 'dev.npy')\n",
        "dev_transcripts_filename = os.path.join(DATA_PATH, 'dev_transcripts_cleaned.txt')\n",
        "\n",
        "test_filename = os.path.join(DATA_PATH, \"test.npy\")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsaqCgDOkmOu"
      },
      "source": [
        "# makes segmenter instance and loads the model file (m.model)\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('train_model_cleaned.model')\n",
        "label_map = [sp.id_to_piece(id) for id in range(sp.get_piece_size())]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2__Yn1wkqMC"
      },
      "source": [
        "class Wav2LetterDataset(Dataset):\n",
        "    def __init__(self, x_path, y_path, sp_model, mean=None, std=None):\n",
        "        stime = time.time()\n",
        "        self.mean = mean.reshape(1, 40)\n",
        "        self.std = std.reshape(1, 40)\n",
        "        self.sp_model = sp_model\n",
        "        with open(y_path, 'r') as file:\n",
        "          y_ = file.read().splitlines()\n",
        "        self.y = [self.sp_model.encode_as_ids(x) for x in y_]\n",
        "        self.X = np.load(x_path, allow_pickle=True)\n",
        "        assert len(self.X)==len(self.y); \"Lengths match!\"\n",
        "        etime = time.time()\n",
        "        print(f\"Loaded the dataset of {len(self.X)} instances in {etime-stime:3.3f} Secs\")\n",
        "        self.length = self.X.shape[0]\n",
        "    def normalize(self, x):\n",
        "        if self.mean is not None and self.std is not None:\n",
        "          return (x-self.mean)/self.std\n",
        "        return x\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = torch.Tensor(self.normalize(self.X[index]))\n",
        "        y = torch.Tensor(self.y[index])\n",
        "        return x, y\n",
        "\n",
        "def pad_collate_(batch):\n",
        "\n",
        "    data = [torch.LongTensor(item[0]) for item in batch]\n",
        "    data_lengths = torch.LongTensor([len(seq) for seq in data])\n",
        "    data = pad_sequence(data)\n",
        "    \n",
        "    max_seqlength = data.shape[0]\n",
        "    input_len_ratio = torch.FloatTensor([item[0].shape[0]/float(max_seqlength) for item in batch])\n",
        "\n",
        "    target = [torch.LongTensor(item[1]) for item in batch]\n",
        "    target_lengths = torch.LongTensor([len(seq) for seq in target])\n",
        "    target = pad_sequence(target, batch_first=True)\n",
        "  \n",
        "    return data, target, data_lengths, target_lengths, input_len_ratio\n",
        "\n",
        "def pad_collate(batch):\n",
        "    inputs = []\n",
        "    inputs_lengths = []\n",
        "    targets = []\n",
        "    targets_lengths = []\n",
        "    for i, (x, y) in enumerate(batch):\n",
        "      inputs.append(x)\n",
        "      inputs_lengths.append(x.shape[0]//2)\n",
        "      targets.append(1 + y) # this is to accomodate for the blank symbol\n",
        "      targets_lengths.append(len(y))\n",
        "    inputs = nn.utils.rnn.pad_sequence(inputs, batch_first=True).transpose(1, 2)\n",
        "    targets = nn.utils.rnn.pad_sequence(targets, batch_first=True)\n",
        "    inputs_lengths = torch.Tensor(inputs_lengths).long()\n",
        "    targets_lengths = torch.Tensor(targets_lengths).long()\n",
        "    return inputs, targets, inputs_lengths, targets_lengths"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOoPdnZRkss9"
      },
      "source": [
        "hyperparameters = {\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 5e-3,\n",
        "    \"weight_decay\": 1e-5,\n",
        "}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdUz7opiVA12"
      },
      "source": [
        "train_mean = np.load(os.path.join(DATA_PATH, 'train_mean.npy'))\n",
        "train_std = np.load(os.path.join(DATA_PATH, 'train_std.npy'))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNImnmfFkvfH",
        "outputId": "80c86057-69d8-4af4-a278-f738dc5b3258"
      },
      "source": [
        "train_data = Wav2LetterDataset(train_filename, train_transcripts_filename, sp_model=sp, mean=train_mean, std=train_std)\n",
        "train_args = dict(shuffle=True, batch_size=hyperparameters[\"batch_size\"], num_workers=num_workers, drop_last=True, collate_fn=pad_collate)\n",
        "train_loader = DataLoader(train_data, **train_args)\n",
        "\n",
        "val_data = Wav2LetterDataset(dev_filename, dev_transcripts_filename, sp_model=sp, mean=train_mean, std=train_std)\n",
        "val_args = dict(shuffle=True, batch_size=hyperparameters[\"batch_size\"], num_workers=num_workers, drop_last=True, collate_fn=pad_collate)\n",
        "val_loader = DataLoader(val_data, **val_args)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the dataset of 5000 instances in 1.795 Secs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded the dataset of 2703 instances in 0.584 Secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ToXZpQVkxSq"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, final=False):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        if not final:\n",
        "          self.relu = nn.ReLU(inplace=True)\n",
        "        else:\n",
        "          self.relu = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        if self.relu:\n",
        "          out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsbruk6OlS6j"
      },
      "source": [
        "class Wav2Letter(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes = 42, num_features = 40):\n",
        "        super(Wav2Letter, self).__init__()\n",
        "\n",
        "        model = nn.Sequential(\n",
        "            ConvBlock(in_channels=num_features, out_channels=250, kernel_size=48, stride=2, padding=23),\n",
        "\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "\n",
        "            ConvBlock(in_channels=250, out_channels=2000, kernel_size=32, stride=1, padding=16),\n",
        "            ConvBlock(in_channels=2000, out_channels=2000, kernel_size=1, stride=1, padding=0),\n",
        "            ConvBlock(in_channels=2000, out_channels=num_classes, kernel_size=1, stride=1, padding=0, final=True)\n",
        "        )\n",
        "        \n",
        "        self.model = model\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Input - (batch_size, num_features, input_length)\n",
        "        out = self.model(x)\n",
        "        out = self.log_softmax(out)\n",
        "        \n",
        "        return out.transpose(0,1)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8tEf2SKlhgz",
        "outputId": "6831b513-d445-4129-c98c-4f0edec587fc"
      },
      "source": [
        "sp.get_piece_size()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFCFcqeplU1W",
        "outputId": "26602ac5-03ef-459a-cbe5-5ae953c8a1ab"
      },
      "source": [
        "model = Wav2Letter(num_classes=sp.get_piece_size()+1)\n",
        "model.to(device)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Wav2Letter(\n",
              "  (model): Sequential(\n",
              "    (0): ConvBlock(\n",
              "      (conv): Conv1d(40, 250, kernel_size=(48,), stride=(2,), padding=(23,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): ConvBlock(\n",
              "      (conv): Conv1d(250, 2000, kernel_size=(32,), stride=(1,), padding=(16,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): ConvBlock(\n",
              "      (conv): Conv1d(2000, 2000, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): ConvBlock(\n",
              "      (conv): Conv1d(2000, 32, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "  )\n",
              "  (log_softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTIk1E2Wl3h1"
      },
      "source": [
        "criterion = nn.CTCLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameters[\"learning_rate\"], weight_decay=hyperparameters[\"weight_decay\"])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5) # OR can use some other scheduler"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_7ixoYRDhCSF",
        "outputId": "41f64141-7998-4bcf-9e20-455c7528e19e"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.8.1+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGq2a902mYUz"
      },
      "source": [
        "# Train the model - Change based on the model\n",
        "\n",
        "def train_model(train_loader, model):\n",
        "    training_loss = 0\n",
        "    \n",
        "    # Set model in 'Training mode'\n",
        "    model.train()\n",
        "    \n",
        "    # enumerate mini batches\n",
        "    for i, (inputs, targets, out_lengths, target_lengths) in enumerate(train_loader):\n",
        "\n",
        "        inputs = inputs.to(device)#.transpose(0,1).transpose(1,2).reshape((hyperparameters[\"batch_size\"], 40, -1))\n",
        "        targets = targets.to(device)\n",
        "        \n",
        "        # clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # compute the model output\n",
        "        out = model(inputs)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = criterion(out.permute(2, 1, 0), targets, out_lengths, target_lengths)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update model weights\n",
        "        optimizer.step()\n",
        "\n",
        "        training_loss += loss.item()\n",
        "        if i%100==0:\n",
        "          print(f\"\\tIteration {i}/{len(train_loader)} and loss: {loss.item()}\")\n",
        "    training_loss /= len(train_loader)\n",
        "    return training_loss"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61YnxHpKmcyQ"
      },
      "source": [
        "# Evaluate the model - Change based on the model\n",
        "\n",
        "def evaluate_model(val_loader, model):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    # enumerate mini batches\n",
        "    total_loss = 0\n",
        "    for i, (inputs, targets, out_lengths, target_lengths ) in enumerate(val_loader):\n",
        "\n",
        "        inputs = inputs.to(device) #.transpose(0,1).transpose(1,2).reshape((hyperparameters[\"batch_size\"], 40, -1)).to(device)        \n",
        "        targets = targets.to(device)\n",
        "        \n",
        "        # compute the model output\n",
        "        out = model(inputs)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = criterion(out.permute(2, 1, 0), targets, out_lengths, target_lengths)\n",
        "\n",
        "        # decoder = CTCBeamDecoder(label_map, beam_width=2, log_probs_input=True)\n",
        "        # out, _, _, out_lengths = decoder.decode(out.transpose(0, 1), out_lengths)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss/len(val_loader)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp4e5i-bnOiS"
      },
      "source": [
        "experiment_name = 'wav2letter_001'"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "4G39sPfnmoQo",
        "outputId": "5672d43d-75c0-46ea-af8a-31ad7de7d728"
      },
      "source": [
        "best_loss = 2**32\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "for epoch in range(hyperparameters[\"epochs\"]):\n",
        "    print(\"Epoch: \", epoch)\n",
        "\n",
        "    # Train\n",
        "    starttime = timeit.default_timer()\n",
        "    training_loss = train_model(train_loader, model)\n",
        "    endtime = timeit.default_timer()\n",
        "    print(\"Training time: \", (endtime - starttime)/60)\n",
        "\n",
        "    # Validation\n",
        "    starttime = timeit.default_timer()\n",
        "    val_loss = evaluate_model(val_loader, model)\n",
        "    endtime = timeit.default_timer()\n",
        "    print(\"Validation time: \", (endtime - starttime)/60, \"and validation loss:\", val_loss)\n",
        "    if val_loss<best_loss:\n",
        "      print(\"Best model is updated......\")\n",
        "      best_loss = val_loss\n",
        "      torch.save(model, os.path.join(MODEL_PATH, f\"{experiment_name}_base_model.pth\"))\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Print log of accuracy and loss\n",
        "    print(\"Epoch: \"+str(epoch)+\", Training loss: \"+str(training_loss)+\", Validation loss: \"+str(val_loss)+\n",
        "          \", LR: \"+str(scheduler.get_last_lr())+\"\\n\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tIteration 0/625 and loss: 2.825741767883301\n",
            "\tIteration 100/625 and loss: 2.867755651473999\n",
            "\tIteration 200/625 and loss: 2.852854013442993\n",
            "\tIteration 300/625 and loss: 2.8600077629089355\n",
            "\tIteration 400/625 and loss: 2.8683714866638184\n",
            "\tIteration 500/625 and loss: 2.869204044342041\n",
            "\tIteration 600/625 and loss: 2.822143077850342\n",
            "Training time:  1.9128743624166722\n",
            "Validation time:  0.29826686001667135 and validation loss: 2.870196056648956\n",
            "Best model is updated......\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-68fb6fefebed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;31m# Print log of accuracy and loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     print(\"Epoch: \"+str(epoch)+\", Training loss: \"+str(training_loss)+\", Validation loss: \"+str(val_loss)+\n\u001b[0;32m---> 25\u001b[0;31m           \", Validation distance: \"+str(val_dist)+\", LR: \"+str(scheduler.get_last_lr())+\"\\n\")\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'val_dist' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASbord8LnrNK",
        "outputId": "9c2b0e4e-cad2-4aee-b888-20cfa7be29d1"
      },
      "source": [
        "for i, (inputs, targets, out_lengths, target_lengths) in enumerate(train_loader):\n",
        "  print(i)\n",
        "  inputs = inputs.to(device)        \n",
        "  targets = targets.to(device)\n",
        "  \n",
        "  # # clear the gradients\n",
        "  # optimizer.zero_grad()\n",
        "  \n",
        "  # compute the model output\n",
        "  out = model(inputs.float())\n",
        "  \n",
        "  # calculate loss\n",
        "  loss = criterion(out.permute(2, 1, 0), targets, out_lengths, target_lengths)\n",
        "  break"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4_Zf7bqMNFe"
      },
      "source": [
        "decoder = CTCBeamDecoder(label_map, beam_width=2, log_probs_input=True)\n",
        "out, _, _, out_lengths = decoder.decode(out.transpose(0, 1), out_lengths)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddUCorBwoCWW",
        "outputId": "6af5f6d2-7deb-4c98-c892-c9067f2f2398"
      },
      "source": [
        "inputs.shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 40, 1336])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi6rMU4KoDOd",
        "outputId": "b2c87b89-878f-46f1-b4b0-52840ee90a1e"
      },
      "source": [
        "out.shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 669])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9MXbFA1oHvx",
        "outputId": "bb035808-8c8a-44ba-e1cf-63ae2622a494"
      },
      "source": [
        "targets.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 237])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDYwqFt4oJRZ",
        "outputId": "9bd2e8f9-42f3-4905-b7f8-8a2b60c27525"
      },
      "source": [
        "target_lengths"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([205, 217,  94, 142, 237, 196, 194, 166])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN6fKvMgoLn_",
        "outputId": "69959b94-3c8e-4ca2-9a3a-65e4435b1161"
      },
      "source": [
        "out_lengths"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[542, 668, 309, 495, 602, 562, 571, 547]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4MlmVm4oQHw",
        "outputId": "27c07607-9c1f-49de-f21d-6a516a071e6c"
      },
      "source": [
        "loss"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(inf, device='cuda:0', grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUdPnxiOohxM",
        "outputId": "3fcfd94c-7875-46c7-bf59-6343071b42f3"
      },
      "source": [
        "out.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 630])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDZN9xe6okse",
        "outputId": "f545c798-ef11-4e91-b91a-f67c44e3ea6b"
      },
      "source": [
        "out"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-2.0789, -2.0788, -2.0790,  ..., -2.0794, -2.0794, -2.0795],\n",
              "         [-2.0790, -2.0791, -2.0791,  ..., -2.0794, -2.0794, -2.0795],\n",
              "         [-2.0789, -2.0790, -2.0791,  ..., -2.0794, -2.0794, -2.0795],\n",
              "         ...,\n",
              "         [-2.0808, -2.0813, -2.0805,  ..., -2.0794, -2.0794, -2.0795],\n",
              "         [-2.0798, -2.0797, -2.0798,  ..., -2.0794, -2.0794, -2.0795],\n",
              "         [-2.0793, -2.0793, -2.0794,  ..., -2.0794, -2.0794, -2.0795]],\n",
              "\n",
              "        [[-2.0792, -2.0793, -2.0792,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0795, -2.0795, -2.0792,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0790, -2.0792, -2.0791,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         ...,\n",
              "         [-2.0802, -2.0795, -2.0803,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0791, -2.0793, -2.0791,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0799, -2.0798, -2.0797,  ..., -2.0794, -2.0794, -2.0794]],\n",
              "\n",
              "        [[-2.0800, -2.0800, -2.0801,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0797, -2.0799, -2.0795,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0798, -2.0800, -2.0798,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         ...,\n",
              "         [-2.0772, -2.0777, -2.0777,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0795, -2.0791, -2.0795,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0798, -2.0792, -2.0791,  ..., -2.0794, -2.0794, -2.0794]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-2.0786, -2.0785, -2.0787,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0790, -2.0788, -2.0793,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0787, -2.0786, -2.0788,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         ...,\n",
              "         [-2.0817, -2.0816, -2.0817,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0800, -2.0797, -2.0792,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0800, -2.0808, -2.0796,  ..., -2.0794, -2.0794, -2.0794]],\n",
              "\n",
              "        [[-2.0794, -2.0794, -2.0794,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0796, -2.0795, -2.0796,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0794, -2.0794, -2.0792,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         ...,\n",
              "         [-2.0797, -2.0795, -2.0797,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0798, -2.0797, -2.0797,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0790, -2.0794, -2.0787,  ..., -2.0794, -2.0794, -2.0794]],\n",
              "\n",
              "        [[-2.0795, -2.0795, -2.0791,  ..., -2.0795, -2.0794, -2.0794],\n",
              "         [-2.0793, -2.0794, -2.0796,  ..., -2.0795, -2.0794, -2.0794],\n",
              "         [-2.0794, -2.0794, -2.0791,  ..., -2.0795, -2.0794, -2.0794],\n",
              "         ...,\n",
              "         [-2.0790, -2.0792, -2.0802,  ..., -2.0795, -2.0794, -2.0794],\n",
              "         [-2.0797, -2.0799, -2.0798,  ..., -2.0795, -2.0794, -2.0794],\n",
              "         [-2.0789, -2.0787, -2.0789,  ..., -2.0795, -2.0794, -2.0794]]],\n",
              "       device='cuda:0', grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXa_rFNwo-B7",
        "outputId": "fbb58e0a-eedd-4133-b1b7-2d8223be5f0d"
      },
      "source": [
        "out1.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 31, 671])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBX7w1W5pfbo",
        "outputId": "07fac9a1-91da-4a1e-9368-c62566085c70"
      },
      "source": [
        "out1"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0026,  0.0026,  0.0024,  ...,  0.0020,  0.0024,  0.0023],\n",
              "         [-0.0086, -0.0087, -0.0086,  ..., -0.0088, -0.0089, -0.0087],\n",
              "         [ 0.0113,  0.0115,  0.0115,  ...,  0.0089,  0.0088,  0.0087],\n",
              "         ...,\n",
              "         [ 0.0057,  0.0054,  0.0055,  ...,  0.0050,  0.0047,  0.0048],\n",
              "         [-0.0061, -0.0064, -0.0064,  ..., -0.0058, -0.0060, -0.0061],\n",
              "         [-0.0313, -0.0308, -0.0304,  ..., -0.0310, -0.0309, -0.0313]],\n",
              "\n",
              "        [[ 0.0027,  0.0024,  0.0024,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0085, -0.0086, -0.0087,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0112,  0.0112,  0.0112,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0055,  0.0054,  0.0053,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0061, -0.0062, -0.0064,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0311, -0.0310, -0.0305,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        [[ 0.0030,  0.0028,  0.0025,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0082, -0.0085, -0.0088,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0111,  0.0113,  0.0112,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0056,  0.0055,  0.0054,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0063, -0.0062, -0.0063,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0309, -0.0307, -0.0303,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.0023,  0.0025,  0.0025,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0085, -0.0089, -0.0091,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0115,  0.0113,  0.0111,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0054,  0.0052,  0.0051,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0067, -0.0069, -0.0068,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0306, -0.0305, -0.0299,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        [[ 0.0028,  0.0025,  0.0026,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0085, -0.0085, -0.0085,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0112,  0.0111,  0.0111,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0054,  0.0053,  0.0055,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0062, -0.0062, -0.0064,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0310, -0.0308, -0.0303,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        [[ 0.0029,  0.0026,  0.0026,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0082, -0.0086, -0.0088,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0114,  0.0114,  0.0116,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0055,  0.0055,  0.0052,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0064, -0.0061, -0.0061,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0309, -0.0309, -0.0307,  ..., -0.0308, -0.0310, -0.0314]]],\n",
              "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3qbSnXXphvb"
      },
      "source": [
        "lgsftmx = nn.LogSoftmax(dim=1)\n",
        "sftmx = nn.Softmax(dim=1)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QUj9mwZptUS",
        "outputId": "fcc1f7df-b7e2-4504-91f1-5c54d7d153ab"
      },
      "source": [
        "lgsftmx(out1)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.4290, -3.4290, -3.4292,  ..., -3.4296, -3.4292, -3.4293],\n",
              "         [-3.4402, -3.4403, -3.4402,  ..., -3.4404, -3.4405, -3.4404],\n",
              "         [-3.4203, -3.4201, -3.4201,  ..., -3.4227, -3.4228, -3.4229],\n",
              "         ...,\n",
              "         [-3.4259, -3.4263, -3.4261,  ..., -3.4267, -3.4269, -3.4268],\n",
              "         [-3.4378, -3.4380, -3.4380,  ..., -3.4374, -3.4376, -3.4377],\n",
              "         [-3.4629, -3.4624, -3.4620,  ..., -3.4626, -3.4625, -3.4629]],\n",
              "\n",
              "        [[-3.4289, -3.4291, -3.4292,  ..., -3.4296, -3.4293, -3.4294],\n",
              "         [-3.4401, -3.4401, -3.4403,  ..., -3.4407, -3.4406, -3.4404],\n",
              "         [-3.4204, -3.4204, -3.4204,  ..., -3.4226, -3.4227, -3.4229],\n",
              "         ...,\n",
              "         [-3.4261, -3.4262, -3.4262,  ..., -3.4266, -3.4268, -3.4267],\n",
              "         [-3.4377, -3.4378, -3.4380,  ..., -3.4376, -3.4378, -3.4378],\n",
              "         [-3.4627, -3.4626, -3.4621,  ..., -3.4624, -3.4626, -3.4629]],\n",
              "\n",
              "        [[-3.4286, -3.4288, -3.4291,  ..., -3.4296, -3.4293, -3.4294],\n",
              "         [-3.4399, -3.4401, -3.4404,  ..., -3.4407, -3.4406, -3.4404],\n",
              "         [-3.4205, -3.4203, -3.4204,  ..., -3.4226, -3.4227, -3.4229],\n",
              "         ...,\n",
              "         [-3.4260, -3.4261, -3.4262,  ..., -3.4266, -3.4268, -3.4267],\n",
              "         [-3.4379, -3.4378, -3.4379,  ..., -3.4376, -3.4378, -3.4378],\n",
              "         [-3.4625, -3.4623, -3.4618,  ..., -3.4624, -3.4626, -3.4629]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-3.4293, -3.4292, -3.4290,  ..., -3.4296, -3.4293, -3.4294],\n",
              "         [-3.4402, -3.4405, -3.4406,  ..., -3.4407, -3.4406, -3.4404],\n",
              "         [-3.4202, -3.4203, -3.4204,  ..., -3.4226, -3.4227, -3.4229],\n",
              "         ...,\n",
              "         [-3.4263, -3.4265, -3.4265,  ..., -3.4266, -3.4268, -3.4267],\n",
              "         [-3.4383, -3.4385, -3.4384,  ..., -3.4376, -3.4378, -3.4378],\n",
              "         [-3.4622, -3.4621, -3.4615,  ..., -3.4624, -3.4626, -3.4629]],\n",
              "\n",
              "        [[-3.4288, -3.4291, -3.4290,  ..., -3.4296, -3.4293, -3.4294],\n",
              "         [-3.4401, -3.4401, -3.4401,  ..., -3.4407, -3.4406, -3.4404],\n",
              "         [-3.4204, -3.4205, -3.4205,  ..., -3.4226, -3.4227, -3.4229],\n",
              "         ...,\n",
              "         [-3.4262, -3.4263, -3.4261,  ..., -3.4266, -3.4268, -3.4267],\n",
              "         [-3.4379, -3.4378, -3.4380,  ..., -3.4376, -3.4378, -3.4378],\n",
              "         [-3.4626, -3.4623, -3.4619,  ..., -3.4624, -3.4626, -3.4629]],\n",
              "\n",
              "        [[-3.4287, -3.4290, -3.4290,  ..., -3.4296, -3.4293, -3.4294],\n",
              "         [-3.4399, -3.4403, -3.4404,  ..., -3.4407, -3.4406, -3.4404],\n",
              "         [-3.4203, -3.4202, -3.4200,  ..., -3.4226, -3.4227, -3.4229],\n",
              "         ...,\n",
              "         [-3.4262, -3.4262, -3.4264,  ..., -3.4266, -3.4268, -3.4267],\n",
              "         [-3.4380, -3.4377, -3.4377,  ..., -3.4376, -3.4378, -3.4378],\n",
              "         [-3.4626, -3.4625, -3.4623,  ..., -3.4624, -3.4626, -3.4629]]],\n",
              "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8TMo9Znpuek",
        "outputId": "e1705b97-4b50-4256-f28a-c280aaabf759"
      },
      "source": [
        "sftmx(out1)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0324, 0.0324, 0.0324,  ..., 0.0324, 0.0324, 0.0324],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0321, 0.0320, 0.0321],\n",
              "         [0.0327, 0.0327, 0.0327,  ..., 0.0326, 0.0326, 0.0326],\n",
              "         ...,\n",
              "         [0.0325, 0.0325, 0.0325,  ..., 0.0325, 0.0325, 0.0325],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0321, 0.0321, 0.0321],\n",
              "         [0.0313, 0.0314, 0.0314,  ..., 0.0313, 0.0314, 0.0313]],\n",
              "\n",
              "        [[0.0324, 0.0324, 0.0324,  ..., 0.0324, 0.0324, 0.0324],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0320, 0.0320, 0.0321],\n",
              "         [0.0327, 0.0327, 0.0327,  ..., 0.0326, 0.0326, 0.0326],\n",
              "         ...,\n",
              "         [0.0325, 0.0325, 0.0325,  ..., 0.0325, 0.0325, 0.0325],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0321, 0.0321, 0.0321],\n",
              "         [0.0313, 0.0313, 0.0314,  ..., 0.0314, 0.0313, 0.0313]],\n",
              "\n",
              "        [[0.0324, 0.0324, 0.0324,  ..., 0.0324, 0.0324, 0.0324],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0320, 0.0320, 0.0321],\n",
              "         [0.0327, 0.0327, 0.0327,  ..., 0.0326, 0.0326, 0.0326],\n",
              "         ...,\n",
              "         [0.0325, 0.0325, 0.0325,  ..., 0.0325, 0.0325, 0.0325],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0321, 0.0321, 0.0321],\n",
              "         [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0313, 0.0313]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.0324, 0.0324, 0.0324,  ..., 0.0324, 0.0324, 0.0324],\n",
              "         [0.0321, 0.0320, 0.0320,  ..., 0.0320, 0.0320, 0.0321],\n",
              "         [0.0327, 0.0327, 0.0327,  ..., 0.0326, 0.0326, 0.0326],\n",
              "         ...,\n",
              "         [0.0325, 0.0325, 0.0325,  ..., 0.0325, 0.0325, 0.0325],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0321, 0.0321, 0.0321],\n",
              "         [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0313, 0.0313]],\n",
              "\n",
              "        [[0.0324, 0.0324, 0.0324,  ..., 0.0324, 0.0324, 0.0324],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0320, 0.0320, 0.0321],\n",
              "         [0.0327, 0.0327, 0.0327,  ..., 0.0326, 0.0326, 0.0326],\n",
              "         ...,\n",
              "         [0.0325, 0.0325, 0.0325,  ..., 0.0325, 0.0325, 0.0325],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0321, 0.0321, 0.0321],\n",
              "         [0.0313, 0.0314, 0.0314,  ..., 0.0314, 0.0313, 0.0313]],\n",
              "\n",
              "        [[0.0324, 0.0324, 0.0324,  ..., 0.0324, 0.0324, 0.0324],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0320, 0.0320, 0.0321],\n",
              "         [0.0327, 0.0327, 0.0327,  ..., 0.0326, 0.0326, 0.0326],\n",
              "         ...,\n",
              "         [0.0325, 0.0325, 0.0325,  ..., 0.0325, 0.0325, 0.0325],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0321, 0.0321, 0.0321],\n",
              "         [0.0313, 0.0314, 0.0314,  ..., 0.0314, 0.0313, 0.0313]]],\n",
              "       device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF6tlz9Hp5kU",
        "outputId": "6a170ffa-e7b7-4992-b811-9e4e82edf11a"
      },
      "source": [
        "out1"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0026,  0.0026,  0.0024,  ...,  0.0020,  0.0024,  0.0023],\n",
              "         [-0.0086, -0.0087, -0.0086,  ..., -0.0088, -0.0089, -0.0087],\n",
              "         [ 0.0113,  0.0115,  0.0115,  ...,  0.0089,  0.0088,  0.0087],\n",
              "         ...,\n",
              "         [ 0.0057,  0.0054,  0.0055,  ...,  0.0050,  0.0047,  0.0048],\n",
              "         [-0.0061, -0.0064, -0.0064,  ..., -0.0058, -0.0060, -0.0061],\n",
              "         [-0.0313, -0.0308, -0.0304,  ..., -0.0310, -0.0309, -0.0313]],\n",
              "\n",
              "        [[ 0.0027,  0.0024,  0.0024,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0085, -0.0086, -0.0087,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0112,  0.0112,  0.0112,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0055,  0.0054,  0.0053,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0061, -0.0062, -0.0064,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0311, -0.0310, -0.0305,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        [[ 0.0030,  0.0028,  0.0025,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0082, -0.0085, -0.0088,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0111,  0.0113,  0.0112,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0056,  0.0055,  0.0054,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0063, -0.0062, -0.0063,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0309, -0.0307, -0.0303,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.0023,  0.0025,  0.0025,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0085, -0.0089, -0.0091,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0115,  0.0113,  0.0111,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0054,  0.0052,  0.0051,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0067, -0.0069, -0.0068,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0306, -0.0305, -0.0299,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        [[ 0.0028,  0.0025,  0.0026,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0085, -0.0085, -0.0085,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0112,  0.0111,  0.0111,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0054,  0.0053,  0.0055,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0062, -0.0062, -0.0064,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0310, -0.0308, -0.0303,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        [[ 0.0029,  0.0026,  0.0026,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0082, -0.0086, -0.0088,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0114,  0.0114,  0.0116,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0055,  0.0055,  0.0052,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0064, -0.0061, -0.0061,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0309, -0.0309, -0.0307,  ..., -0.0308, -0.0310, -0.0314]]],\n",
              "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uikSoEap73Y",
        "outputId": "6ac66f91-fea5-487a-c7a9-c1c1a60ad019"
      },
      "source": [
        "inputs[0].max(dim=1)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(values=tensor([ 10,  37,  99, 152,  48,  93, 149, 267, 184,  69,  60,  17,  25,  22,\n",
              "         30,  17,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  47,  35,  27,  14,  13,  43,  28,  12,   8,  14],\n",
              "       device='cuda:0'), ...)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVSa36N3scil",
        "outputId": "e8e1aa75-a5b0-4c8c-84b6-5b7ada2cd2c7"
      },
      "source": [
        "global_feats = np.zeros(40)\n",
        "gloabl_std = np.zeros(40)\n",
        "for i, x in enumerate(train_data.X):\n",
        "  global_mean += np.mean(x, 1)\n"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S9d4B4fsppR"
      },
      "source": [
        "tmp_ = np.concatenate(train_data.X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guirkgc7tkOw"
      },
      "source": [
        "tmp_.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a9slJsIpcNG"
      },
      "source": [
        "criterion = nn.CTCLoss().to(device)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_-neTUrtli3"
      },
      "source": [
        "loss = criterion(out, targets, out_lengths, target_lengths)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBKzsD8npTqv",
        "outputId": "5d746b9a-d481-4a5d-c7c1-257719b5e48e"
      },
      "source": [
        "loss.item()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8sHm1PMpUUZ",
        "outputId": "98315dc1-6915-4d67-e039-37ef6d858ad6"
      },
      "source": [
        "out.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 630])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj_cuTZVpfFF",
        "outputId": "f6a648b7-324e-4266-db6b-e9335f021dfb"
      },
      "source": [
        "targets"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3,  6,  8,  ...,  0,  0,  0],\n",
              "        [ 3, 18, 10,  ..., 19,  5, 10],\n",
              "        [ 3, 21,  7,  ...,  0,  0,  0],\n",
              "        ...,\n",
              "        [ 3, 20,  4,  ...,  0,  0,  0],\n",
              "        [ 3, 17,  6,  ...,  0,  0,  0],\n",
              "        [ 3,  9,  5,  ...,  0,  0,  0]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULebx6o8pg2c",
        "outputId": "2f96cf96-5f0c-4bf7-f9a6-ded4818f36bd"
      },
      "source": [
        "out_lengths"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([32, 29, 13, 17, 25, 29, 27, 17], dtype=torch.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrg-E3hRp9cw",
        "outputId": "6bc7e10d-23f3-458b-fe0d-018f9417bc60"
      },
      "source": [
        "inputs.dtype"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNLVNQoHy64N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}