{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Wav2Letter++.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPvpCFqtJ3MN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f569560-884e-43ef-da39-dc6d0e03cbb3"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Apr  9 08:28:26 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   70C    P8    11W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlQiXTwKi5am",
        "outputId": "3cb11b89-22aa-4826-f978-9f5b57ba45db"
      },
      "source": [
        "!pip install sentencepiece"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncrjElbMiwrC"
      },
      "source": [
        "import sentencepiece as spm"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fwp1-zBii3a-",
        "outputId": "15fa1e19-852c-4976-efdb-4963f3cfa260"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pi5f903ySZw0",
        "outputId": "e2c82278-83d2-4ef2-f225-6f9d1b4096fa"
      },
      "source": [
        "ls gdrive/MyDrive/idl_proj/data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.npy                      test.npy        train_std2.npy\n",
            "dev.npy.zip                  test.npy.zip    train_std.npy\n",
            "dev_transcripts_cleaned.txt  train_mean.npy  train_transcripts_cleaned_mini.txt\n",
            "dev_transcripts.npy          train_mini.npy  train_transcripts_cleaned.txt\n",
            "sample.csv                   train.npy       train_transcripts.npy\n",
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/                 train.npy.zip   train_transcripts.npy.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "macsrPxci9Nm",
        "outputId": "e65b56bf-de31-4a51-9fd5-3555890348bd"
      },
      "source": [
        "cd /content/gdrive/MyDrive/idl_proj/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/MyDrive/idl_proj\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_gn_oz2jD8k",
        "outputId": "567382f5-dd71-438c-d7f8-e4cd03843fb2"
      },
      "source": [
        "ls data"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dev.npy                      test.npy        train_std2.npy\n",
            "dev.npy.zip                  test.npy.zip    train_std.npy\n",
            "dev_transcripts_cleaned.txt  train_mean.npy  train_transcripts_cleaned_mini.txt\n",
            "dev_transcripts.npy          train_mini.npy  train_transcripts_cleaned.txt\n",
            "sample.csv                   train.npy       train_transcripts.npy\n",
            "\u001b[0m\u001b[01;34msample_data\u001b[0m/                 train.npy.zip   train_transcripts.npy.zip\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exk3MZ-WjNug"
      },
      "source": [
        "import os"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSolDD2NjHZf"
      },
      "source": [
        "BASE_PATH = \"/content/gdrive/MyDrive/idl_proj/\"\n",
        "DATA_PATH = os.path.join(BASE_PATH, \"data\")\n",
        "MODEL_PATH = os.path.join(BASE_PATH, \"models\")\n",
        "PREDICTION_PATH = os.path.join(BASE_PATH, \"predictions\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoiq_uQLjOk4"
      },
      "source": [
        "# # Installing CTC Decoder\n",
        "# !git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "# !cd ctcdecode && pip install ."
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOC0fRfNkzjG"
      },
      "source": [
        "import time"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAynC33HjRfZ"
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import timeit\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch.optim as optim\n",
        "from torch.nn.utils.rnn import *\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "from datetime import datetime as dt"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nW6KLLbfjX6K",
        "outputId": "209b2fa5-3f97-49e3-a911-9a4a608582ec"
      },
      "source": [
        "# Check if cuda is available\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "num_workers = 4 if cuda else 0\n",
        "print(\"Cuda = \"+str(cuda)+\" with num_workers = \"+str(num_workers))\n",
        "\n",
        "def get_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = 'cuda:0'\n",
        "    else:\n",
        "        device = 'cpu'\n",
        "    return device\n",
        "device = get_device()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda = True with num_workers = 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqiJfle3kfAE"
      },
      "source": [
        "# Files from drive\n",
        "train_filename = os.path.join(DATA_PATH, 'train.npy')\n",
        "train_transcripts_filename = os.path.join(DATA_PATH, 'train_transcripts_cleaned.txt')\n",
        "\n",
        "dev_filename = os.path.join(DATA_PATH, 'dev.npy')\n",
        "dev_transcripts_filename = os.path.join(DATA_PATH, 'dev_transcripts_cleaned.txt')\n",
        "\n",
        "test_filename = os.path.join(DATA_PATH, \"test.npy\")"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsaqCgDOkmOu"
      },
      "source": [
        "# makes segmenter instance and loads the model file (m.model)\n",
        "sp = spm.SentencePieceProcessor()\n",
        "sp.load('train_model_cleaned.model')\n",
        "label_map = [sp.id_to_piece(id) for id in range(sp.get_piece_size())]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2__Yn1wkqMC"
      },
      "source": [
        "class Wav2LetterDataset(Dataset):\n",
        "    def __init__(self, x_path, y_path, sp_model, mean=None, std=None):\n",
        "        stime = time.time()\n",
        "        self.mean = mean.reshape(1, 40)\n",
        "        self.std = std.reshape(1, 40)\n",
        "        self.sp_model = sp_model\n",
        "        with open(y_path, 'r') as file:\n",
        "          y_ = file.read().splitlines()\n",
        "        self.y = [self.sp_model.encode_as_ids(x) for x in y_]\n",
        "        self.X = np.load(x_path, allow_pickle=True)\n",
        "        assert len(self.X)==len(self.y); \"Lengths match!\"\n",
        "        etime = time.time()\n",
        "        print(f\"Loaded the dataset of {len(self.X)} instances in {etime-stime:3.3f} Secs\")\n",
        "        self.length = self.X.shape[0]\n",
        "    def normalize(self, x):\n",
        "        if self.mean is not None and self.std is not None:\n",
        "          return (x-self.mean)/self.std\n",
        "        return x\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = torch.Tensor(self.normalize(self.X[index]))\n",
        "        y = torch.Tensor(self.y[index])\n",
        "        return x, y\n",
        "\n",
        "def pad_collate_(batch):\n",
        "\n",
        "    data = [torch.LongTensor(item[0]) for item in batch]\n",
        "    data_lengths = torch.LongTensor([len(seq) for seq in data])\n",
        "    data = pad_sequence(data)\n",
        "    \n",
        "    max_seqlength = data.shape[0]\n",
        "    input_len_ratio = torch.FloatTensor([item[0].shape[0]/float(max_seqlength) for item in batch])\n",
        "\n",
        "    target = [torch.LongTensor(item[1]) for item in batch]\n",
        "    target_lengths = torch.LongTensor([len(seq) for seq in target])\n",
        "    target = pad_sequence(target, batch_first=True)\n",
        "  \n",
        "    return data, target, data_lengths, target_lengths, input_len_ratio\n",
        "\n",
        "def pad_collate(batch):\n",
        "    inputs = []\n",
        "    inputs_lengths = []\n",
        "    targets = []\n",
        "    targets_lengths = []\n",
        "    for i, (x, y) in enumerate(batch):\n",
        "      inputs.append(x)\n",
        "      inputs_lengths.append(x.shape[0]//2)\n",
        "      targets.append(1 + y) # this is to accomodate for the blank symbol\n",
        "      targets_lengths.append(len(y))\n",
        "    inputs = nn.utils.rnn.pad_sequence(inputs, batch_first=True).transpose(1, 2)\n",
        "    targets = nn.utils.rnn.pad_sequence(targets, batch_first=True)\n",
        "    inputs_lengths = torch.Tensor(inputs_lengths).long()\n",
        "    targets_lengths = torch.Tensor(targets_lengths).long()\n",
        "    return inputs, targets, inputs_lengths, targets_lengths"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOoPdnZRkss9"
      },
      "source": [
        "hyperparameters = {\n",
        "    \"batch_size\": 8,\n",
        "    \"epochs\": 50,\n",
        "    \"learning_rate\": 1e-3,\n",
        "    \"weight_decay\": 1e-5,\n",
        "}"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdUz7opiVA12"
      },
      "source": [
        "train_mean = np.load(os.path.join(DATA_PATH, 'train_mean.npy'))\n",
        "train_std = np.load(os.path.join(DATA_PATH, 'train_std.npy'))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNImnmfFkvfH",
        "outputId": "4124955c-84ef-4a61-bf23-081453220f41"
      },
      "source": [
        "train_data = Wav2LetterDataset(train_filename, train_transcripts_filename, sp_model=sp, mean=train_mean, std=train_std)\n",
        "train_args = dict(shuffle=True, batch_size=hyperparameters[\"batch_size\"], num_workers=num_workers, drop_last=True, collate_fn=pad_collate)\n",
        "train_loader = DataLoader(train_data, **train_args)\n",
        "\n",
        "val_data = Wav2LetterDataset(dev_filename, dev_transcripts_filename, sp_model=sp, mean=train_mean, std=train_std)\n",
        "val_args = dict(shuffle=True, batch_size=hyperparameters[\"batch_size\"], num_workers=num_workers, drop_last=True, collate_fn=pad_collate)\n",
        "val_loader = DataLoader(val_data, **val_args)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded the dataset of 28539 instances in 129.485 Secs\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loaded the dataset of 2703 instances in 0.564 Secs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ToXZpQVkxSq"
      },
      "source": [
        "class ConvBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding, final=False):\n",
        "        super(ConvBlock, self).__init__()\n",
        "        self.conv = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "        if not final:\n",
        "          self.relu = nn.ReLU(inplace=True)\n",
        "        else:\n",
        "          self.relu = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        if self.relu:\n",
        "          out = self.relu(out)\n",
        "\n",
        "        return out"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsbruk6OlS6j"
      },
      "source": [
        "class Wav2Letter(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes = 42, num_features = 40):\n",
        "        super(Wav2Letter, self).__init__()\n",
        "\n",
        "        model = nn.Sequential(\n",
        "            ConvBlock(in_channels=num_features, out_channels=250, kernel_size=48, stride=2, padding=23),\n",
        "\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
        "\n",
        "            ConvBlock(in_channels=250, out_channels=2000, kernel_size=32, stride=1, padding=16),\n",
        "            ConvBlock(in_channels=2000, out_channels=2000, kernel_size=1, stride=1, padding=0),\n",
        "            ConvBlock(in_channels=2000, out_channels=num_classes, kernel_size=1, stride=1, padding=0, final=True)\n",
        "        )\n",
        "        \n",
        "        self.model = model\n",
        "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        # Input - (batch_size, num_features, input_length)\n",
        "        out = self.model(x)\n",
        "        out = self.log_softmax(out)\n",
        "        \n",
        "        return out.transpose(0,1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8tEf2SKlhgz",
        "outputId": "1cc23b90-a2cc-4408-cabe-c962f64b8667"
      },
      "source": [
        "sp.get_piece_size()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFCFcqeplU1W",
        "outputId": "2d9d58f7-b75f-4249-b5ad-b99592170ee7"
      },
      "source": [
        "model = Wav2Letter(num_classes=sp.get_piece_size()+1)\n",
        "model.to(device)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Wav2Letter(\n",
              "  (model): Sequential(\n",
              "    (0): ConvBlock(\n",
              "      (conv): Conv1d(40, 250, kernel_size=(48,), stride=(2,), padding=(23,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (1): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (3): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (4): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (5): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (6): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (7): ConvBlock(\n",
              "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (8): ConvBlock(\n",
              "      (conv): Conv1d(250, 2000, kernel_size=(32,), stride=(1,), padding=(16,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (9): ConvBlock(\n",
              "      (conv): Conv1d(2000, 2000, kernel_size=(1,), stride=(1,))\n",
              "      (relu): ReLU(inplace=True)\n",
              "    )\n",
              "    (10): ConvBlock(\n",
              "      (conv): Conv1d(2000, 32, kernel_size=(1,), stride=(1,))\n",
              "    )\n",
              "  )\n",
              "  (log_softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTIk1E2Wl3h1"
      },
      "source": [
        "criterion = nn.CTCLoss().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=hyperparameters[\"learning_rate\"], weight_decay=hyperparameters[\"weight_decay\"])\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.1, patience=5) # OR can use some other scheduler"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_7ixoYRDhCSF",
        "outputId": "0546822f-59cc-47f3-9963-64e06cd5d0ce"
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.8.1+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGq2a902mYUz"
      },
      "source": [
        "# Train the model - Change based on the model\n",
        "\n",
        "def train_model(train_loader, model):\n",
        "    training_loss = 0\n",
        "    \n",
        "    # Set model in 'Training mode'\n",
        "    model.train()\n",
        "    \n",
        "    # enumerate mini batches\n",
        "    for i, (inputs, targets, out_lengths, target_lengths) in enumerate(train_loader):\n",
        "\n",
        "        inputs = inputs.to(device)#.transpose(0,1).transpose(1,2).reshape((hyperparameters[\"batch_size\"], 40, -1))\n",
        "        targets = targets.to(device)\n",
        "        \n",
        "        # clear the gradients\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # compute the model output\n",
        "        out = model(inputs)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = criterion(out.permute(2, 1, 0), targets, out_lengths, target_lengths)\n",
        "        \n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update model weights\n",
        "        optimizer.step()\n",
        "\n",
        "        training_loss += loss.item()\n",
        "        if i%100==0:\n",
        "          print(f\"\\tIteration {i}/{len(train_loader)} and loss: {loss.item()}\")\n",
        "    training_loss /= len(train_loader)\n",
        "    return training_loss"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61YnxHpKmcyQ"
      },
      "source": [
        "# Evaluate the model - Change based on the model\n",
        "\n",
        "def evaluate_model(val_loader, model):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    # enumerate mini batches\n",
        "    total_loss = 0\n",
        "    for i, (inputs, targets, out_lengths, target_lengths ) in enumerate(val_loader):\n",
        "\n",
        "        inputs = inputs.to(device) #.transpose(0,1).transpose(1,2).reshape((hyperparameters[\"batch_size\"], 40, -1)).to(device)        \n",
        "        targets = targets.to(device)\n",
        "        \n",
        "        # compute the model output\n",
        "        out = model(inputs)\n",
        "        \n",
        "        # calculate loss\n",
        "        loss = criterion(out.permute(2, 1, 0), targets, out_lengths, target_lengths)\n",
        "\n",
        "        # decoder = CTCBeamDecoder(label_map, beam_width=2, log_probs_input=True)\n",
        "        # out, _, _, out_lengths = decoder.decode(out.transpose(0, 1), out_lengths)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss/len(val_loader)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qp4e5i-bnOiS"
      },
      "source": [
        "experiment_name = 'wav2letter_002'"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4G39sPfnmoQo",
        "outputId": "dfeb0d26-4c97-47ba-b0ae-30102b6c2a78"
      },
      "source": [
        "best_loss = 2**32\n",
        "os.makedirs(MODEL_PATH, exist_ok=True)\n",
        "for epoch in range(hyperparameters[\"epochs\"]):\n",
        "    print(\"Epoch: \", epoch)\n",
        "\n",
        "    # Train\n",
        "    starttime = timeit.default_timer()\n",
        "    training_loss = train_model(train_loader, model)\n",
        "    endtime = timeit.default_timer()\n",
        "    print(\"Training time: \", (endtime - starttime)/60)\n",
        "\n",
        "    # Validation\n",
        "    starttime = timeit.default_timer()\n",
        "    val_loss = evaluate_model(val_loader, model)\n",
        "    endtime = timeit.default_timer()\n",
        "    print(\"Validation time: \", (endtime - starttime)/60, \"and validation loss:\", val_loss)\n",
        "    if val_loss<best_loss:\n",
        "      print(\"Best model is updated......\")\n",
        "      best_loss = val_loss\n",
        "      torch.save(model, os.path.join(MODEL_PATH, f\"{experiment_name}_base_model.pth\"))\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "    # Print log of accuracy and loss\n",
        "    print(\"Epoch: \"+str(epoch)+\", Training loss: \"+str(training_loss)+\", Validation loss: \"+str(val_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:  0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\tIteration 0/3567 and loss: 7.892758846282959\n",
            "\tIteration 100/3567 and loss: 3.729721784591675\n",
            "\tIteration 200/3567 and loss: 3.0274624824523926\n",
            "\tIteration 300/3567 and loss: 2.8373637199401855\n",
            "\tIteration 400/3567 and loss: 2.838928699493408\n",
            "\tIteration 500/3567 and loss: 2.832183361053467\n",
            "\tIteration 600/3567 and loss: 2.788273811340332\n",
            "\tIteration 700/3567 and loss: 2.7223682403564453\n",
            "\tIteration 800/3567 and loss: 2.7525720596313477\n",
            "\tIteration 900/3567 and loss: 2.807286262512207\n",
            "\tIteration 1000/3567 and loss: 2.7188100814819336\n",
            "\tIteration 1100/3567 and loss: 2.774825096130371\n",
            "\tIteration 1200/3567 and loss: 2.636594533920288\n",
            "\tIteration 1300/3567 and loss: 2.7132158279418945\n",
            "\tIteration 1400/3567 and loss: 2.6724257469177246\n",
            "\tIteration 1500/3567 and loss: 2.658158540725708\n",
            "\tIteration 1600/3567 and loss: 2.700549364089966\n",
            "\tIteration 1700/3567 and loss: 2.5961458683013916\n",
            "\tIteration 1800/3567 and loss: 2.612863779067993\n",
            "\tIteration 1900/3567 and loss: 2.5649991035461426\n",
            "\tIteration 2000/3567 and loss: 2.5691308975219727\n",
            "\tIteration 2100/3567 and loss: 2.626089572906494\n",
            "\tIteration 2200/3567 and loss: 2.5837221145629883\n",
            "\tIteration 2300/3567 and loss: 2.6040968894958496\n",
            "\tIteration 2400/3567 and loss: 2.553562879562378\n",
            "\tIteration 2500/3567 and loss: 2.5487961769104004\n",
            "\tIteration 2600/3567 and loss: 2.518085479736328\n",
            "\tIteration 2700/3567 and loss: 2.539602279663086\n",
            "\tIteration 2800/3567 and loss: 2.592434883117676\n",
            "\tIteration 2900/3567 and loss: 2.5222816467285156\n",
            "\tIteration 3000/3567 and loss: 2.657712459564209\n",
            "\tIteration 3100/3567 and loss: 2.612225294113159\n",
            "\tIteration 3200/3567 and loss: 2.60105562210083\n",
            "\tIteration 3300/3567 and loss: 2.5396502017974854\n",
            "\tIteration 3400/3567 and loss: 2.622069835662842\n",
            "\tIteration 3500/3567 and loss: 2.5149354934692383\n",
            "Training time:  10.9674697892667\n",
            "Validation time:  0.3053370923500552 and validation loss: 2.596740173656792\n",
            "Best model is updated......\n",
            "Epoch: 0, Training loss: 2.7807185578352938, Validation loss: 2.596740173656792\n",
            "Epoch:  1\n",
            "\tIteration 0/3567 and loss: 2.56406307220459\n",
            "\tIteration 100/3567 and loss: 2.557910919189453\n",
            "\tIteration 200/3567 and loss: 2.4820330142974854\n",
            "\tIteration 300/3567 and loss: 2.512951374053955\n",
            "\tIteration 400/3567 and loss: 2.572636604309082\n",
            "\tIteration 500/3567 and loss: 2.5944156646728516\n",
            "\tIteration 600/3567 and loss: 2.503448486328125\n",
            "\tIteration 700/3567 and loss: 2.519338607788086\n",
            "\tIteration 800/3567 and loss: 2.5468387603759766\n",
            "\tIteration 900/3567 and loss: 2.5570473670959473\n",
            "\tIteration 1000/3567 and loss: 2.5642426013946533\n",
            "\tIteration 1100/3567 and loss: 2.4868640899658203\n",
            "\tIteration 1200/3567 and loss: 2.5289998054504395\n",
            "\tIteration 1300/3567 and loss: 2.585130214691162\n",
            "\tIteration 1400/3567 and loss: 2.5027761459350586\n",
            "\tIteration 1500/3567 and loss: 2.5680346488952637\n",
            "\tIteration 1600/3567 and loss: 2.5632810592651367\n",
            "\tIteration 1700/3567 and loss: 2.4992942810058594\n",
            "\tIteration 1800/3567 and loss: 2.463625431060791\n",
            "\tIteration 1900/3567 and loss: 2.564943313598633\n",
            "\tIteration 2000/3567 and loss: 2.5005455017089844\n",
            "\tIteration 2100/3567 and loss: 2.5477652549743652\n",
            "\tIteration 2200/3567 and loss: 2.560750722885132\n",
            "\tIteration 2300/3567 and loss: 2.51121187210083\n",
            "\tIteration 2400/3567 and loss: 2.450284004211426\n",
            "\tIteration 2500/3567 and loss: 2.4842023849487305\n",
            "\tIteration 2600/3567 and loss: 2.4946560859680176\n",
            "\tIteration 2700/3567 and loss: 2.5465962886810303\n",
            "\tIteration 2800/3567 and loss: 2.4813365936279297\n",
            "\tIteration 2900/3567 and loss: 2.5381932258605957\n",
            "\tIteration 3000/3567 and loss: 2.5365569591522217\n",
            "\tIteration 3100/3567 and loss: 2.44875168800354\n",
            "\tIteration 3200/3567 and loss: 2.5565876960754395\n",
            "\tIteration 3300/3567 and loss: 2.491755485534668\n",
            "\tIteration 3400/3567 and loss: 2.4846956729888916\n",
            "\tIteration 3500/3567 and loss: 2.4948906898498535\n",
            "Training time:  10.93626221571667\n",
            "Validation time:  0.3094870558999901 and validation loss: 2.5811323008834433\n",
            "Best model is updated......\n",
            "Epoch: 1, Training loss: 2.528672443039116, Validation loss: 2.5811323008834433\n",
            "Epoch:  2\n",
            "\tIteration 0/3567 and loss: 2.4965291023254395\n",
            "\tIteration 100/3567 and loss: 2.536569595336914\n",
            "\tIteration 200/3567 and loss: 2.485320806503296\n",
            "\tIteration 300/3567 and loss: 2.5238494873046875\n",
            "\tIteration 400/3567 and loss: 2.5767972469329834\n",
            "\tIteration 500/3567 and loss: 2.5160727500915527\n",
            "\tIteration 600/3567 and loss: 2.4992356300354004\n",
            "\tIteration 700/3567 and loss: 2.5945887565612793\n",
            "\tIteration 800/3567 and loss: 2.561082601547241\n",
            "\tIteration 900/3567 and loss: 2.4631266593933105\n",
            "\tIteration 1000/3567 and loss: 2.4890685081481934\n",
            "\tIteration 1100/3567 and loss: 2.494326591491699\n",
            "\tIteration 1200/3567 and loss: 2.494837522506714\n",
            "\tIteration 1300/3567 and loss: 2.5102720260620117\n",
            "\tIteration 1400/3567 and loss: 2.491865873336792\n",
            "\tIteration 1500/3567 and loss: 2.5121474266052246\n",
            "\tIteration 1600/3567 and loss: 2.5067219734191895\n",
            "\tIteration 1700/3567 and loss: 2.517458438873291\n",
            "\tIteration 1800/3567 and loss: 2.5318820476531982\n",
            "\tIteration 1900/3567 and loss: 2.514709711074829\n",
            "\tIteration 2000/3567 and loss: 2.5424704551696777\n",
            "\tIteration 2100/3567 and loss: 2.62923002243042\n",
            "\tIteration 2200/3567 and loss: 2.548267364501953\n",
            "\tIteration 2300/3567 and loss: 2.5667290687561035\n",
            "\tIteration 2400/3567 and loss: 2.48563289642334\n",
            "\tIteration 2500/3567 and loss: 2.514446973800659\n",
            "\tIteration 2600/3567 and loss: 2.4926161766052246\n",
            "\tIteration 2700/3567 and loss: 2.531311511993408\n",
            "\tIteration 2800/3567 and loss: 2.5516202449798584\n",
            "\tIteration 2900/3567 and loss: 2.48367977142334\n",
            "\tIteration 3000/3567 and loss: 2.5083322525024414\n",
            "\tIteration 3100/3567 and loss: 2.5145201683044434\n",
            "\tIteration 3200/3567 and loss: 2.466909646987915\n",
            "\tIteration 3300/3567 and loss: 2.6219980716705322\n",
            "\tIteration 3400/3567 and loss: 2.717717170715332\n",
            "\tIteration 3500/3567 and loss: 2.7107224464416504\n",
            "Training time:  10.860157987533361\n",
            "Validation time:  0.30560774808333613 and validation loss: 2.704657242630639\n",
            "Epoch: 2, Training loss: 2.5236703212567995, Validation loss: 2.704657242630639\n",
            "Epoch:  3\n",
            "\tIteration 0/3567 and loss: 2.70117449760437\n",
            "\tIteration 100/3567 and loss: 2.8413796424865723\n",
            "\tIteration 200/3567 and loss: 2.7842745780944824\n",
            "\tIteration 300/3567 and loss: 2.8587400913238525\n",
            "\tIteration 400/3567 and loss: 2.8382487297058105\n",
            "\tIteration 500/3567 and loss: 2.922619342803955\n",
            "\tIteration 600/3567 and loss: 2.600712776184082\n",
            "\tIteration 700/3567 and loss: 2.5788893699645996\n",
            "\tIteration 800/3567 and loss: 2.558675765991211\n",
            "\tIteration 900/3567 and loss: 2.634899377822876\n",
            "\tIteration 1000/3567 and loss: 2.4843196868896484\n",
            "\tIteration 1100/3567 and loss: 2.6183178424835205\n",
            "\tIteration 1200/3567 and loss: 2.5595359802246094\n",
            "\tIteration 1300/3567 and loss: 2.4885659217834473\n",
            "\tIteration 1400/3567 and loss: 2.4830048084259033\n",
            "\tIteration 1500/3567 and loss: 2.4725332260131836\n",
            "\tIteration 1600/3567 and loss: 2.450261354446411\n",
            "\tIteration 1700/3567 and loss: 2.5736489295959473\n",
            "\tIteration 1800/3567 and loss: 2.535841941833496\n",
            "\tIteration 1900/3567 and loss: 2.495023250579834\n",
            "\tIteration 2000/3567 and loss: 2.5220284461975098\n",
            "\tIteration 2100/3567 and loss: 2.4984264373779297\n",
            "\tIteration 2200/3567 and loss: 2.618819236755371\n",
            "\tIteration 2300/3567 and loss: 2.4436511993408203\n",
            "\tIteration 2400/3567 and loss: 2.527235269546509\n",
            "\tIteration 2500/3567 and loss: 2.4442527294158936\n",
            "\tIteration 2600/3567 and loss: 2.5400900840759277\n",
            "\tIteration 2700/3567 and loss: 2.517427921295166\n",
            "\tIteration 2800/3567 and loss: 2.496056079864502\n",
            "\tIteration 2900/3567 and loss: 2.55607271194458\n",
            "\tIteration 3000/3567 and loss: 2.4707159996032715\n",
            "\tIteration 3100/3567 and loss: 2.5503392219543457\n",
            "\tIteration 3200/3567 and loss: 2.4881768226623535\n",
            "\tIteration 3300/3567 and loss: 2.4615612030029297\n",
            "\tIteration 3400/3567 and loss: 2.566758155822754\n",
            "\tIteration 3500/3567 and loss: 2.592071533203125\n",
            "Training time:  10.804853775733317\n",
            "Validation time:  0.3034415685166702 and validation loss: 2.5846548603974746\n",
            "Epoch: 3, Training loss: 2.600223901126777, Validation loss: 2.5846548603974746\n",
            "Epoch:  4\n",
            "\tIteration 0/3567 and loss: 2.4758188724517822\n",
            "\tIteration 100/3567 and loss: 2.5346550941467285\n",
            "\tIteration 200/3567 and loss: 2.5746028423309326\n",
            "\tIteration 300/3567 and loss: 2.567215919494629\n",
            "\tIteration 400/3567 and loss: 2.5379648208618164\n",
            "\tIteration 500/3567 and loss: 2.453136920928955\n",
            "\tIteration 600/3567 and loss: 2.5273609161376953\n",
            "\tIteration 700/3567 and loss: 2.599104881286621\n",
            "\tIteration 800/3567 and loss: 2.4975929260253906\n",
            "\tIteration 900/3567 and loss: 2.5083436965942383\n",
            "\tIteration 1000/3567 and loss: 2.4676268100738525\n",
            "\tIteration 1100/3567 and loss: 2.8529791831970215\n",
            "\tIteration 1200/3567 and loss: 2.8395490646362305\n",
            "\tIteration 1300/3567 and loss: 2.858610153198242\n",
            "\tIteration 1400/3567 and loss: 2.8356456756591797\n",
            "\tIteration 1500/3567 and loss: 2.7812163829803467\n",
            "\tIteration 1600/3567 and loss: 2.5103864669799805\n",
            "\tIteration 1700/3567 and loss: 2.4343791007995605\n",
            "\tIteration 1800/3567 and loss: 2.492018461227417\n",
            "\tIteration 1900/3567 and loss: 2.5540857315063477\n",
            "\tIteration 2000/3567 and loss: 2.652247905731201\n",
            "\tIteration 2100/3567 and loss: 2.4671056270599365\n",
            "\tIteration 2200/3567 and loss: 2.4740240573883057\n",
            "\tIteration 2300/3567 and loss: 2.5542807579040527\n",
            "\tIteration 2400/3567 and loss: 2.5686306953430176\n",
            "\tIteration 2500/3567 and loss: 2.4378488063812256\n",
            "\tIteration 2600/3567 and loss: 2.503817558288574\n",
            "\tIteration 2700/3567 and loss: 2.5267868041992188\n",
            "\tIteration 2800/3567 and loss: 2.4937946796417236\n",
            "\tIteration 2900/3567 and loss: 2.5437817573547363\n",
            "\tIteration 3000/3567 and loss: 2.602638006210327\n",
            "\tIteration 3100/3567 and loss: 2.547792911529541\n",
            "\tIteration 3200/3567 and loss: 2.535719394683838\n",
            "\tIteration 3300/3567 and loss: 2.4759788513183594\n",
            "\tIteration 3400/3567 and loss: 2.5963711738586426\n",
            "\tIteration 3500/3567 and loss: 2.502880334854126\n",
            "Training time:  10.796808596783375\n",
            "Validation time:  0.3041822098666671 and validation loss: 2.5838687278396653\n",
            "Epoch: 4, Training loss: 2.673920780996799, Validation loss: 2.5838687278396653\n",
            "Epoch:  5\n",
            "\tIteration 0/3567 and loss: 2.624457359313965\n",
            "\tIteration 100/3567 and loss: 2.5576014518737793\n",
            "\tIteration 200/3567 and loss: 2.8700389862060547\n",
            "\tIteration 300/3567 and loss: 2.5757389068603516\n",
            "\tIteration 400/3567 and loss: 2.5401978492736816\n",
            "\tIteration 500/3567 and loss: 2.5364346504211426\n",
            "\tIteration 600/3567 and loss: 2.4371285438537598\n",
            "\tIteration 700/3567 and loss: 2.4873719215393066\n",
            "\tIteration 800/3567 and loss: 2.562410831451416\n",
            "\tIteration 900/3567 and loss: 2.489304542541504\n",
            "\tIteration 1000/3567 and loss: 2.562607526779175\n",
            "\tIteration 1100/3567 and loss: 2.566861152648926\n",
            "\tIteration 1200/3567 and loss: 2.5391252040863037\n",
            "\tIteration 1300/3567 and loss: 2.613218307495117\n",
            "\tIteration 1400/3567 and loss: 2.5023488998413086\n",
            "\tIteration 1500/3567 and loss: 2.854496955871582\n",
            "\tIteration 1600/3567 and loss: 2.667999267578125\n",
            "\tIteration 1700/3567 and loss: 2.550663948059082\n",
            "\tIteration 1800/3567 and loss: 2.592740058898926\n",
            "\tIteration 1900/3567 and loss: 2.5614876747131348\n",
            "\tIteration 2000/3567 and loss: 2.5652503967285156\n",
            "\tIteration 2100/3567 and loss: 2.5870790481567383\n",
            "\tIteration 2200/3567 and loss: 2.5539536476135254\n",
            "\tIteration 2300/3567 and loss: 2.513875961303711\n",
            "\tIteration 2400/3567 and loss: 2.5282647609710693\n",
            "\tIteration 2500/3567 and loss: 2.5057973861694336\n",
            "\tIteration 2600/3567 and loss: 2.535327911376953\n",
            "\tIteration 2700/3567 and loss: 2.5338213443756104\n",
            "\tIteration 2800/3567 and loss: 2.5043046474456787\n",
            "\tIteration 2900/3567 and loss: 2.5471253395080566\n",
            "\tIteration 3000/3567 and loss: 2.4580931663513184\n",
            "\tIteration 3100/3567 and loss: 2.5849947929382324\n",
            "\tIteration 3200/3567 and loss: 2.5173983573913574\n",
            "\tIteration 3300/3567 and loss: 2.517676591873169\n",
            "\tIteration 3400/3567 and loss: 2.5061163902282715\n",
            "\tIteration 3500/3567 and loss: 2.5173075199127197\n",
            "Training time:  10.799469722033367\n",
            "Validation time:  0.30255935588332555 and validation loss: 2.6001638991188933\n",
            "Epoch: 5, Training loss: 2.630469607010187, Validation loss: 2.6001638991188933\n",
            "Epoch:  6\n",
            "\tIteration 0/3567 and loss: 2.460728168487549\n",
            "\tIteration 100/3567 and loss: 2.510197162628174\n",
            "\tIteration 200/3567 and loss: 2.5642876625061035\n",
            "\tIteration 300/3567 and loss: 2.5089287757873535\n",
            "\tIteration 400/3567 and loss: 2.5432679653167725\n",
            "\tIteration 500/3567 and loss: 2.548447608947754\n",
            "\tIteration 600/3567 and loss: 2.556684970855713\n",
            "\tIteration 700/3567 and loss: 2.4860634803771973\n",
            "\tIteration 800/3567 and loss: 2.7567873001098633\n",
            "\tIteration 900/3567 and loss: 2.508246898651123\n",
            "\tIteration 1000/3567 and loss: 2.5057363510131836\n",
            "\tIteration 1100/3567 and loss: 2.606719493865967\n",
            "\tIteration 1200/3567 and loss: 2.593277931213379\n",
            "\tIteration 1300/3567 and loss: 2.7178635597229004\n",
            "\tIteration 1400/3567 and loss: 2.564948320388794\n",
            "\tIteration 1500/3567 and loss: 2.518977165222168\n",
            "\tIteration 1600/3567 and loss: 2.5128891468048096\n",
            "\tIteration 1700/3567 and loss: 2.5123705863952637\n",
            "\tIteration 1800/3567 and loss: 2.521533727645874\n",
            "\tIteration 1900/3567 and loss: 2.483710289001465\n",
            "\tIteration 2000/3567 and loss: 2.527912139892578\n",
            "\tIteration 2100/3567 and loss: 2.461533546447754\n",
            "\tIteration 2200/3567 and loss: 2.5036942958831787\n",
            "\tIteration 2300/3567 and loss: 2.4898757934570312\n",
            "\tIteration 2400/3567 and loss: 2.4816203117370605\n",
            "\tIteration 2500/3567 and loss: 2.526858329772949\n",
            "\tIteration 2600/3567 and loss: 2.51478910446167\n",
            "\tIteration 2700/3567 and loss: 2.52773380279541\n",
            "\tIteration 2800/3567 and loss: 2.701022148132324\n",
            "\tIteration 2900/3567 and loss: 2.6515278816223145\n",
            "\tIteration 3000/3567 and loss: 2.5017590522766113\n",
            "\tIteration 3100/3567 and loss: 2.5448198318481445\n",
            "\tIteration 3200/3567 and loss: 2.5264663696289062\n",
            "\tIteration 3300/3567 and loss: 2.5841472148895264\n",
            "\tIteration 3400/3567 and loss: 2.5404720306396484\n",
            "\tIteration 3500/3567 and loss: 2.435905933380127\n",
            "Training time:  10.819619198449981\n",
            "Validation time:  0.3075753173833315 and validation loss: 2.5968323708995515\n",
            "Epoch: 6, Training loss: 2.634324254527091, Validation loss: 2.5968323708995515\n",
            "Epoch:  7\n",
            "\tIteration 0/3567 and loss: 2.5391111373901367\n",
            "\tIteration 100/3567 and loss: 2.56518292427063\n",
            "\tIteration 200/3567 and loss: 2.5602035522460938\n",
            "\tIteration 300/3567 and loss: 2.5831708908081055\n",
            "\tIteration 400/3567 and loss: 2.4981062412261963\n",
            "\tIteration 500/3567 and loss: 2.4875011444091797\n",
            "\tIteration 600/3567 and loss: 2.478634834289551\n",
            "\tIteration 700/3567 and loss: 2.5088791847229004\n",
            "\tIteration 800/3567 and loss: 2.4492197036743164\n",
            "\tIteration 900/3567 and loss: 2.5533950328826904\n",
            "\tIteration 1000/3567 and loss: 2.4934298992156982\n",
            "\tIteration 1100/3567 and loss: 2.4793362617492676\n",
            "\tIteration 1200/3567 and loss: 2.4895715713500977\n",
            "\tIteration 1300/3567 and loss: 2.5047190189361572\n",
            "\tIteration 1400/3567 and loss: 2.860334873199463\n",
            "\tIteration 1500/3567 and loss: 2.874559164047241\n",
            "\tIteration 1600/3567 and loss: 2.7958884239196777\n",
            "\tIteration 1700/3567 and loss: 2.829993486404419\n",
            "\tIteration 1800/3567 and loss: 2.868124008178711\n",
            "\tIteration 1900/3567 and loss: 2.954803943634033\n",
            "\tIteration 2000/3567 and loss: 2.850703716278076\n",
            "\tIteration 2100/3567 and loss: 2.8584303855895996\n",
            "\tIteration 2200/3567 and loss: 2.837446689605713\n",
            "\tIteration 2300/3567 and loss: 2.83103084564209\n",
            "\tIteration 2400/3567 and loss: 2.8202567100524902\n",
            "\tIteration 2500/3567 and loss: 2.81978702545166\n",
            "\tIteration 2600/3567 and loss: 2.814608573913574\n",
            "\tIteration 2700/3567 and loss: 2.7919960021972656\n",
            "\tIteration 2800/3567 and loss: 2.816236734390259\n",
            "\tIteration 2900/3567 and loss: 2.8640406131744385\n",
            "\tIteration 3000/3567 and loss: 2.8210344314575195\n",
            "\tIteration 3100/3567 and loss: 2.8137428760528564\n",
            "\tIteration 3200/3567 and loss: 2.8010215759277344\n",
            "\tIteration 3300/3567 and loss: 2.872112274169922\n",
            "\tIteration 3400/3567 and loss: 2.857687473297119\n",
            "\tIteration 3500/3567 and loss: 2.8656246662139893\n",
            "Training time:  10.715212445083306\n",
            "Validation time:  0.30472377671667344 and validation loss: 2.8465338467844163\n",
            "Epoch: 7, Training loss: 2.715147404968822, Validation loss: 2.8465338467844163\n",
            "Epoch:  8\n",
            "\tIteration 0/3567 and loss: 2.8294575214385986\n",
            "\tIteration 100/3567 and loss: 2.8519015312194824\n",
            "\tIteration 200/3567 and loss: 2.8350892066955566\n",
            "\tIteration 300/3567 and loss: 2.8206887245178223\n",
            "\tIteration 400/3567 and loss: 2.825774669647217\n",
            "\tIteration 500/3567 and loss: 2.8528456687927246\n",
            "\tIteration 600/3567 and loss: 2.850937843322754\n",
            "\tIteration 700/3567 and loss: 2.853029489517212\n",
            "\tIteration 800/3567 and loss: 2.834731101989746\n",
            "\tIteration 900/3567 and loss: 2.83516788482666\n",
            "\tIteration 1000/3567 and loss: 2.8287839889526367\n",
            "\tIteration 1100/3567 and loss: 2.823232650756836\n",
            "\tIteration 1200/3567 and loss: 2.8267154693603516\n",
            "\tIteration 1300/3567 and loss: 2.813579559326172\n",
            "\tIteration 1400/3567 and loss: 2.8335494995117188\n",
            "\tIteration 1500/3567 and loss: 2.817877769470215\n",
            "\tIteration 1600/3567 and loss: 2.8309319019317627\n",
            "\tIteration 1700/3567 and loss: 2.8503949642181396\n",
            "\tIteration 1800/3567 and loss: 2.857893466949463\n",
            "\tIteration 1900/3567 and loss: 2.8461050987243652\n",
            "\tIteration 2000/3567 and loss: 2.8149826526641846\n",
            "\tIteration 2100/3567 and loss: 2.820992946624756\n",
            "\tIteration 2200/3567 and loss: 2.812253952026367\n",
            "\tIteration 2300/3567 and loss: 2.861071825027466\n",
            "\tIteration 2400/3567 and loss: 2.795596122741699\n",
            "\tIteration 2500/3567 and loss: 2.829890727996826\n",
            "\tIteration 2600/3567 and loss: 2.847374439239502\n",
            "\tIteration 2700/3567 and loss: 2.8167083263397217\n",
            "\tIteration 2800/3567 and loss: 2.828503131866455\n",
            "\tIteration 2900/3567 and loss: 2.8073501586914062\n",
            "\tIteration 3000/3567 and loss: 2.833411693572998\n",
            "\tIteration 3100/3567 and loss: 2.8437108993530273\n",
            "\tIteration 3200/3567 and loss: 2.8514022827148438\n",
            "\tIteration 3300/3567 and loss: 2.846967935562134\n",
            "\tIteration 3400/3567 and loss: 2.8274807929992676\n",
            "\tIteration 3500/3567 and loss: 2.851242780685425\n",
            "Training time:  10.625129664883328\n",
            "Validation time:  0.2984662828999717 and validation loss: 2.8455726937653405\n",
            "Epoch: 8, Training loss: 2.83263190854722, Validation loss: 2.8455726937653405\n",
            "Epoch:  9\n",
            "\tIteration 0/3567 and loss: 2.8428587913513184\n",
            "\tIteration 100/3567 and loss: 2.7972731590270996\n",
            "\tIteration 200/3567 and loss: 2.905775785446167\n",
            "\tIteration 300/3567 and loss: 2.8164610862731934\n",
            "\tIteration 400/3567 and loss: 2.8308446407318115\n",
            "\tIteration 500/3567 and loss: 2.8397250175476074\n",
            "\tIteration 600/3567 and loss: 2.8309881687164307\n",
            "\tIteration 700/3567 and loss: 2.84130597114563\n",
            "\tIteration 800/3567 and loss: 2.83028244972229\n",
            "\tIteration 900/3567 and loss: 2.825063467025757\n",
            "\tIteration 1000/3567 and loss: 2.811445474624634\n",
            "\tIteration 1100/3567 and loss: 2.8276607990264893\n",
            "\tIteration 1200/3567 and loss: 2.8064651489257812\n",
            "\tIteration 1300/3567 and loss: 2.7421627044677734\n",
            "\tIteration 1400/3567 and loss: 2.8303027153015137\n",
            "\tIteration 1500/3567 and loss: 2.8893771171569824\n",
            "\tIteration 1600/3567 and loss: 2.8780996799468994\n",
            "\tIteration 1700/3567 and loss: 2.7782793045043945\n",
            "\tIteration 1800/3567 and loss: 2.8196487426757812\n",
            "\tIteration 1900/3567 and loss: 2.83902645111084\n",
            "\tIteration 2000/3567 and loss: 2.8556604385375977\n",
            "\tIteration 2100/3567 and loss: 2.799015760421753\n",
            "\tIteration 2200/3567 and loss: 2.8317489624023438\n",
            "\tIteration 2300/3567 and loss: 2.7841129302978516\n",
            "\tIteration 2400/3567 and loss: 2.8313679695129395\n",
            "\tIteration 2500/3567 and loss: 2.8004841804504395\n",
            "\tIteration 2600/3567 and loss: 2.878488063812256\n",
            "\tIteration 2700/3567 and loss: 2.7954745292663574\n",
            "\tIteration 2800/3567 and loss: 2.8118605613708496\n",
            "\tIteration 2900/3567 and loss: 2.823939561843872\n",
            "\tIteration 3000/3567 and loss: 2.842301845550537\n",
            "\tIteration 3100/3567 and loss: 2.8790318965911865\n",
            "\tIteration 3200/3567 and loss: 2.829580783843994\n",
            "\tIteration 3300/3567 and loss: 2.8974175453186035\n",
            "\tIteration 3400/3567 and loss: 2.824422836303711\n",
            "\tIteration 3500/3567 and loss: 2.8108835220336914\n",
            "Training time:  10.635519420700014\n",
            "Validation time:  0.30202255894995084 and validation loss: 2.843268464510094\n",
            "Epoch: 9, Training loss: 2.8315995563002305, Validation loss: 2.843268464510094\n",
            "Epoch:  10\n",
            "\tIteration 0/3567 and loss: 2.8249707221984863\n",
            "\tIteration 100/3567 and loss: 2.817111015319824\n",
            "\tIteration 200/3567 and loss: 2.8397626876831055\n",
            "\tIteration 300/3567 and loss: 2.875943183898926\n",
            "\tIteration 400/3567 and loss: 2.8200833797454834\n",
            "\tIteration 500/3567 and loss: 2.8187294006347656\n",
            "\tIteration 600/3567 and loss: 2.8483262062072754\n",
            "\tIteration 700/3567 and loss: 2.8564367294311523\n",
            "\tIteration 800/3567 and loss: 2.826045513153076\n",
            "\tIteration 900/3567 and loss: 2.824495315551758\n",
            "\tIteration 1000/3567 and loss: 2.842550754547119\n",
            "\tIteration 1100/3567 and loss: 2.8282151222229004\n",
            "\tIteration 1200/3567 and loss: 2.801197052001953\n",
            "\tIteration 1300/3567 and loss: 2.7766075134277344\n",
            "\tIteration 1400/3567 and loss: 2.7979040145874023\n",
            "\tIteration 1500/3567 and loss: 2.8184852600097656\n",
            "\tIteration 1600/3567 and loss: 2.793757438659668\n",
            "\tIteration 1700/3567 and loss: 2.8185529708862305\n",
            "\tIteration 1800/3567 and loss: 2.7914047241210938\n",
            "\tIteration 1900/3567 and loss: 2.824901580810547\n",
            "\tIteration 2000/3567 and loss: 2.794414520263672\n",
            "\tIteration 2100/3567 and loss: 2.8184282779693604\n",
            "\tIteration 2200/3567 and loss: 2.8330934047698975\n",
            "\tIteration 2300/3567 and loss: 2.8353867530822754\n",
            "\tIteration 2400/3567 and loss: 2.813204765319824\n",
            "\tIteration 2500/3567 and loss: 2.8204994201660156\n",
            "\tIteration 2600/3567 and loss: 2.8530900478363037\n",
            "\tIteration 2700/3567 and loss: 2.844846725463867\n",
            "\tIteration 2800/3567 and loss: 2.847635269165039\n",
            "\tIteration 2900/3567 and loss: 2.810751438140869\n",
            "\tIteration 3000/3567 and loss: 2.828354835510254\n",
            "\tIteration 3100/3567 and loss: 2.857083320617676\n",
            "\tIteration 3200/3567 and loss: 2.8427395820617676\n",
            "\tIteration 3300/3567 and loss: 2.863600969314575\n",
            "\tIteration 3400/3567 and loss: 2.8004980087280273\n",
            "\tIteration 3500/3567 and loss: 2.8596725463867188\n",
            "Training time:  10.657465447833358\n",
            "Validation time:  0.30235812636662257 and validation loss: 2.8438341143576964\n",
            "Epoch: 10, Training loss: 2.8303920071700523, Validation loss: 2.8438341143576964\n",
            "Epoch:  11\n",
            "\tIteration 0/3567 and loss: 2.832974672317505\n",
            "\tIteration 100/3567 and loss: 2.8302464485168457\n",
            "\tIteration 200/3567 and loss: 2.8095810413360596\n",
            "\tIteration 300/3567 and loss: 2.7908246517181396\n",
            "\tIteration 400/3567 and loss: 2.871616840362549\n",
            "\tIteration 500/3567 and loss: 2.8550753593444824\n",
            "\tIteration 600/3567 and loss: 2.7867751121520996\n",
            "\tIteration 700/3567 and loss: 2.893901824951172\n",
            "\tIteration 800/3567 and loss: 2.832759141921997\n",
            "\tIteration 900/3567 and loss: 2.8431358337402344\n",
            "\tIteration 1000/3567 and loss: 2.843994140625\n",
            "\tIteration 1100/3567 and loss: 2.853219985961914\n",
            "\tIteration 1200/3567 and loss: 2.873398780822754\n",
            "\tIteration 1300/3567 and loss: 2.859682321548462\n",
            "\tIteration 1400/3567 and loss: 2.8283638954162598\n",
            "\tIteration 1500/3567 and loss: 2.83241868019104\n",
            "\tIteration 1600/3567 and loss: 2.844972610473633\n",
            "\tIteration 1700/3567 and loss: 2.8700175285339355\n",
            "\tIteration 1800/3567 and loss: 2.7883975505828857\n",
            "\tIteration 1900/3567 and loss: 2.7965126037597656\n",
            "\tIteration 2000/3567 and loss: 2.5338172912597656\n",
            "\tIteration 2100/3567 and loss: 2.647540330886841\n",
            "\tIteration 2200/3567 and loss: 2.447330951690674\n",
            "\tIteration 2300/3567 and loss: 2.5453429222106934\n",
            "\tIteration 2400/3567 and loss: 2.5203092098236084\n",
            "\tIteration 2500/3567 and loss: 2.507256031036377\n",
            "\tIteration 2600/3567 and loss: 2.5388660430908203\n",
            "\tIteration 2700/3567 and loss: 2.4807677268981934\n",
            "\tIteration 2800/3567 and loss: 2.5005340576171875\n",
            "\tIteration 2900/3567 and loss: 2.5267772674560547\n",
            "\tIteration 3000/3567 and loss: 2.4937596321105957\n",
            "\tIteration 3100/3567 and loss: 2.446357488632202\n",
            "\tIteration 3200/3567 and loss: 2.4537229537963867\n",
            "\tIteration 3300/3567 and loss: 2.5413880348205566\n",
            "\tIteration 3400/3567 and loss: 2.573324680328369\n",
            "\tIteration 3500/3567 and loss: 2.5773394107818604\n",
            "Training time:  10.78663844816668\n",
            "Validation time:  0.3055608902666184 and validation loss: 2.582346253296034\n",
            "Epoch: 11, Training loss: 2.6877565889222166, Validation loss: 2.582346253296034\n",
            "Epoch:  12\n",
            "\tIteration 0/3567 and loss: 2.527653694152832\n",
            "\tIteration 100/3567 and loss: 2.533780097961426\n",
            "\tIteration 200/3567 and loss: 2.505188226699829\n",
            "\tIteration 300/3567 and loss: 2.555712938308716\n",
            "\tIteration 400/3567 and loss: 2.5513343811035156\n",
            "\tIteration 500/3567 and loss: 2.555276393890381\n",
            "\tIteration 600/3567 and loss: 2.521790027618408\n",
            "\tIteration 700/3567 and loss: 2.614893674850464\n",
            "\tIteration 800/3567 and loss: 2.4899497032165527\n",
            "\tIteration 900/3567 and loss: 2.478447437286377\n",
            "\tIteration 1000/3567 and loss: 2.4826135635375977\n",
            "\tIteration 1100/3567 and loss: 2.52050518989563\n",
            "\tIteration 1200/3567 and loss: 2.48380708694458\n",
            "\tIteration 1300/3567 and loss: 2.494086742401123\n",
            "\tIteration 1400/3567 and loss: 2.433567523956299\n",
            "\tIteration 1500/3567 and loss: 2.5080630779266357\n",
            "\tIteration 1600/3567 and loss: 2.51400089263916\n",
            "\tIteration 1700/3567 and loss: 2.43558406829834\n",
            "\tIteration 1800/3567 and loss: 2.5043540000915527\n",
            "\tIteration 1900/3567 and loss: 2.48996901512146\n",
            "\tIteration 2000/3567 and loss: 2.464573860168457\n",
            "\tIteration 2100/3567 and loss: 2.5078907012939453\n",
            "\tIteration 2200/3567 and loss: 2.457766532897949\n",
            "\tIteration 2300/3567 and loss: 2.5948939323425293\n",
            "\tIteration 2400/3567 and loss: 2.5071229934692383\n",
            "\tIteration 2500/3567 and loss: 2.5003879070281982\n",
            "\tIteration 2600/3567 and loss: 2.501150608062744\n",
            "\tIteration 2700/3567 and loss: 2.555215358734131\n",
            "\tIteration 2800/3567 and loss: 2.5603413581848145\n",
            "\tIteration 2900/3567 and loss: 2.4533793926239014\n",
            "\tIteration 3000/3567 and loss: 2.5208983421325684\n",
            "\tIteration 3100/3567 and loss: 2.4343690872192383\n",
            "\tIteration 3200/3567 and loss: 2.4724373817443848\n",
            "\tIteration 3300/3567 and loss: 2.553816795349121\n",
            "\tIteration 3400/3567 and loss: 2.5781641006469727\n",
            "\tIteration 3500/3567 and loss: 2.5570948123931885\n",
            "Training time:  10.961332243516638\n",
            "Validation time:  0.309127186750023 and validation loss: 2.553384344372622\n",
            "Best model is updated......\n",
            "Epoch: 12, Training loss: 2.5026852539817526, Validation loss: 2.553384344372622\n",
            "Epoch:  13\n",
            "\tIteration 0/3567 and loss: 2.4428353309631348\n",
            "\tIteration 100/3567 and loss: 2.468113899230957\n",
            "\tIteration 200/3567 and loss: 2.524374008178711\n",
            "\tIteration 300/3567 and loss: 2.4958343505859375\n",
            "\tIteration 400/3567 and loss: 2.4966065883636475\n",
            "\tIteration 500/3567 and loss: 2.497584342956543\n",
            "\tIteration 600/3567 and loss: 2.4640932083129883\n",
            "\tIteration 700/3567 and loss: 2.5546984672546387\n",
            "\tIteration 800/3567 and loss: 2.5044984817504883\n",
            "\tIteration 900/3567 and loss: 2.487793445587158\n",
            "\tIteration 1000/3567 and loss: 2.562326431274414\n",
            "\tIteration 1100/3567 and loss: 2.5160412788391113\n",
            "\tIteration 1200/3567 and loss: 2.478334426879883\n",
            "\tIteration 1300/3567 and loss: 2.4641332626342773\n",
            "\tIteration 1400/3567 and loss: 2.5707247257232666\n",
            "\tIteration 1500/3567 and loss: 2.4894235134124756\n",
            "\tIteration 1600/3567 and loss: 2.492922306060791\n",
            "\tIteration 1700/3567 and loss: 2.519192695617676\n",
            "\tIteration 1800/3567 and loss: 2.4810662269592285\n",
            "\tIteration 1900/3567 and loss: 2.516388177871704\n",
            "\tIteration 2000/3567 and loss: 2.4797000885009766\n",
            "\tIteration 2100/3567 and loss: 2.5104479789733887\n",
            "\tIteration 2200/3567 and loss: 2.5268330574035645\n",
            "\tIteration 2300/3567 and loss: 2.5295233726501465\n",
            "\tIteration 2400/3567 and loss: 2.476156711578369\n",
            "\tIteration 2500/3567 and loss: 2.514549970626831\n",
            "\tIteration 2600/3567 and loss: 2.4597277641296387\n",
            "\tIteration 2700/3567 and loss: 2.5707345008850098\n",
            "\tIteration 2800/3567 and loss: 2.587567090988159\n",
            "\tIteration 2900/3567 and loss: 2.486286163330078\n",
            "\tIteration 3000/3567 and loss: 2.580310344696045\n",
            "\tIteration 3100/3567 and loss: 2.513620376586914\n",
            "\tIteration 3200/3567 and loss: 2.447049140930176\n",
            "\tIteration 3300/3567 and loss: 2.4506425857543945\n",
            "\tIteration 3400/3567 and loss: 2.511441946029663\n",
            "\tIteration 3500/3567 and loss: 2.56272554397583\n",
            "Training time:  10.969912431766716\n",
            "Validation time:  0.303013402316598 and validation loss: 2.555523358042233\n",
            "Epoch: 13, Training loss: 2.501471041429935, Validation loss: 2.555523358042233\n",
            "Epoch:  14\n",
            "\tIteration 0/3567 and loss: 2.5467286109924316\n",
            "\tIteration 100/3567 and loss: 2.466144561767578\n",
            "\tIteration 200/3567 and loss: 2.4920434951782227\n",
            "\tIteration 300/3567 and loss: 2.518706798553467\n",
            "\tIteration 400/3567 and loss: 2.460308313369751\n",
            "\tIteration 500/3567 and loss: 2.5020816326141357\n",
            "\tIteration 600/3567 and loss: 2.433262348175049\n",
            "\tIteration 700/3567 and loss: 2.540086507797241\n",
            "\tIteration 800/3567 and loss: 2.4418861865997314\n",
            "\tIteration 900/3567 and loss: 2.443058967590332\n",
            "\tIteration 1000/3567 and loss: 2.4783833026885986\n",
            "\tIteration 1100/3567 and loss: 2.506859302520752\n",
            "\tIteration 1200/3567 and loss: 2.4430153369903564\n",
            "\tIteration 1300/3567 and loss: 2.479982852935791\n",
            "\tIteration 1400/3567 and loss: 2.4746155738830566\n",
            "\tIteration 1500/3567 and loss: 2.525040626525879\n",
            "\tIteration 1600/3567 and loss: 2.4667582511901855\n",
            "\tIteration 1700/3567 and loss: 2.447765588760376\n",
            "\tIteration 1800/3567 and loss: 2.517824172973633\n",
            "\tIteration 1900/3567 and loss: 2.4207818508148193\n",
            "\tIteration 2000/3567 and loss: 2.4974617958068848\n",
            "\tIteration 2100/3567 and loss: 2.433053970336914\n",
            "\tIteration 2200/3567 and loss: 2.4410619735717773\n",
            "\tIteration 2300/3567 and loss: 2.453725814819336\n",
            "\tIteration 2400/3567 and loss: 2.4649672508239746\n",
            "\tIteration 2500/3567 and loss: 2.457392454147339\n",
            "\tIteration 2600/3567 and loss: 2.5261101722717285\n",
            "\tIteration 2700/3567 and loss: 2.45625638961792\n",
            "\tIteration 2800/3567 and loss: 2.5257349014282227\n",
            "\tIteration 2900/3567 and loss: 2.5935211181640625\n",
            "\tIteration 3000/3567 and loss: 2.521847724914551\n",
            "\tIteration 3100/3567 and loss: 2.5225417613983154\n",
            "\tIteration 3200/3567 and loss: 2.439420223236084\n",
            "\tIteration 3300/3567 and loss: 2.491800546646118\n",
            "\tIteration 3400/3567 and loss: 2.5170583724975586\n",
            "\tIteration 3500/3567 and loss: 2.509437084197998\n",
            "Training time:  10.957343631149948\n",
            "Validation time:  0.2982646972833512 and validation loss: 2.560361915243132\n",
            "Epoch: 14, Training loss: 2.4950952257199686, Validation loss: 2.560361915243132\n",
            "Epoch:  15\n",
            "\tIteration 0/3567 and loss: 2.503511905670166\n",
            "\tIteration 100/3567 and loss: 2.5328660011291504\n",
            "\tIteration 200/3567 and loss: 2.5262532234191895\n",
            "\tIteration 300/3567 and loss: 2.563554286956787\n",
            "\tIteration 400/3567 and loss: 2.4925928115844727\n",
            "\tIteration 500/3567 and loss: 2.4848766326904297\n",
            "\tIteration 600/3567 and loss: 2.4972801208496094\n",
            "\tIteration 700/3567 and loss: 2.470963954925537\n",
            "\tIteration 800/3567 and loss: 2.4920852184295654\n",
            "\tIteration 900/3567 and loss: 2.492896556854248\n",
            "\tIteration 1000/3567 and loss: 2.4521613121032715\n",
            "\tIteration 1100/3567 and loss: 2.53352689743042\n",
            "\tIteration 1200/3567 and loss: 2.5200018882751465\n",
            "\tIteration 1300/3567 and loss: 2.4396920204162598\n",
            "\tIteration 1400/3567 and loss: 2.4914169311523438\n",
            "\tIteration 1500/3567 and loss: 2.516118288040161\n",
            "\tIteration 1600/3567 and loss: 2.465691089630127\n",
            "\tIteration 1700/3567 and loss: 2.454247236251831\n",
            "\tIteration 1800/3567 and loss: 2.4983222484588623\n",
            "\tIteration 1900/3567 and loss: 2.545438051223755\n",
            "\tIteration 2000/3567 and loss: 2.46545672416687\n",
            "\tIteration 2100/3567 and loss: 2.5402445793151855\n",
            "\tIteration 2200/3567 and loss: 2.5436272621154785\n",
            "\tIteration 2300/3567 and loss: 2.5548319816589355\n",
            "\tIteration 2400/3567 and loss: 2.5376646518707275\n",
            "\tIteration 2500/3567 and loss: 2.4618663787841797\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "ASbord8LnrNK",
        "outputId": "e17bd468-1199-4e45-f752-c448df66c7d9"
      },
      "source": [
        "for i, (inputs, targets, out_lengths, target_lengths) in enumerate(train_loader):\n",
        "  print(i)\n",
        "  inputs = inputs.to(device)        \n",
        "  targets = targets.to(device)\n",
        "  \n",
        "  # # clear the gradients\n",
        "  # optimizer.zero_grad()\n",
        "  \n",
        "  # compute the model output\n",
        "  out = model(inputs.float())\n",
        "  \n",
        "  # calculate loss\n",
        "  loss = criterion(out.permute(2, 1, 0), targets, out_lengths, target_lengths)\n",
        "  break"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-157a6beb24e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_lengths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_lengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ3IXZAZStU0"
      },
      "source": [
        "# len(['_']+label_map), out.transpose(1, 0).shape"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4_Zf7bqMNFe"
      },
      "source": [
        "\n",
        "try:\n",
        "  decoder = CTCBeamDecoder(['_']+label_map, beam_width=2, log_probs_input=True)\n",
        "  beam_results, beam_scores, timesteps, out_lens = decoder.decode(out.permute(1, 2, 0), out_lengths)\n",
        "except Exception as e:\n",
        "  print(e)"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-W4TmdwlTjLC",
        "outputId": "3dc99304-208f-4006-fb58-383990e89306"
      },
      "source": [
        "beam_results"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[          4,           4,           4,  ...,  1027105801,\n",
              "           1012500714,  1023749098],\n",
              "         [          4,           4,           4,  ...,  1025910930,\n",
              "           1024386452,  1024865761]],\n",
              "\n",
              "        [[          4,           4,           4,  ...,  1024218641,\n",
              "           1024428950,  1026603728],\n",
              "         [          4,           4,           4,  ...,   973573062,\n",
              "            985360338,  1024232018]],\n",
              "\n",
              "        [[          4,           4,           4,  ...,  1026681854,\n",
              "           1020103964,  1026717739],\n",
              "         [          4,           4,           4,  ..., -1128611165,\n",
              "          -1130233222, -1123592753]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[          4,           4,           4,  ...,  1008263857,\n",
              "           1018299607,  1020890171],\n",
              "         [          4,           4,           4,  ..., -1124877065,\n",
              "           1018980746,  1015357430]],\n",
              "\n",
              "        [[          4,           4,           4,  ...,  1024762339,\n",
              "           1025255684,  1023436226],\n",
              "         [          4,           4,           4,  ..., -1123102587,\n",
              "           1024314676,  1012714088]],\n",
              "\n",
              "        [[          4,           4,           4,  ...,  1019474934,\n",
              "           1024959033,  1011858767],\n",
              "         [          4,           4,           4,  ...,  1024103143,\n",
              "           1027209802,  1015905754]]], dtype=torch.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fEFZrMUUNju",
        "outputId": "5fa14306-a604-4b0e-c468-0fab3619d163"
      },
      "source": [
        "for i in range(2):\n",
        "     print(sp.decode_ids(beam_results[0][i][:out_lens[0][i]].detach().numpy().tolist()))"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "eeeeeeeeee\n",
            "eeeeeeeee\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddUCorBwoCWW",
        "outputId": "6af5f6d2-7deb-4c98-c892-c9067f2f2398"
      },
      "source": [
        "inputs.shape"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 40, 1336])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xi6rMU4KoDOd",
        "outputId": "b2c87b89-878f-46f1-b4b0-52840ee90a1e"
      },
      "source": [
        "out.shape"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 669])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9MXbFA1oHvx",
        "outputId": "bb035808-8c8a-44ba-e1cf-63ae2622a494"
      },
      "source": [
        "targets.shape"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 237])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zDYwqFt4oJRZ",
        "outputId": "9bd2e8f9-42f3-4905-b7f8-8a2b60c27525"
      },
      "source": [
        "target_lengths"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([205, 217,  94, 142, 237, 196, 194, 166])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PN6fKvMgoLn_",
        "outputId": "69959b94-3c8e-4ca2-9a3a-65e4435b1161"
      },
      "source": [
        "out_lengths"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[542, 668, 309, 495, 602, 562, 571, 547]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4MlmVm4oQHw",
        "outputId": "27c07607-9c1f-49de-f21d-6a516a071e6c"
      },
      "source": [
        "loss"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(inf, device='cuda:0', grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUdPnxiOohxM",
        "outputId": "3fcfd94c-7875-46c7-bf59-6343071b42f3"
      },
      "source": [
        "out.shape"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 630])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDZN9xe6okse",
        "outputId": "f545c798-ef11-4e91-b91a-f67c44e3ea6b"
      },
      "source": [
        "out"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-2.0789, -2.0788, -2.0790,  ..., -2.0794, -2.0794, -2.0795],\n",
              "         [-2.0790, -2.0791, -2.0791,  ..., -2.0794, -2.0794, -2.0795],\n",
              "         [-2.0789, -2.0790, -2.0791,  ..., -2.0794, -2.0794, -2.0795],\n",
              "         ...,\n",
              "         [-2.0808, -2.0813, -2.0805,  ..., -2.0794, -2.0794, -2.0795],\n",
              "         [-2.0798, -2.0797, -2.0798,  ..., -2.0794, -2.0794, -2.0795],\n",
              "         [-2.0793, -2.0793, -2.0794,  ..., -2.0794, -2.0794, -2.0795]],\n",
              "\n",
              "        [[-2.0792, -2.0793, -2.0792,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0795, -2.0795, -2.0792,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0790, -2.0792, -2.0791,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         ...,\n",
              "         [-2.0802, -2.0795, -2.0803,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0791, -2.0793, -2.0791,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0799, -2.0798, -2.0797,  ..., -2.0794, -2.0794, -2.0794]],\n",
              "\n",
              "        [[-2.0800, -2.0800, -2.0801,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0797, -2.0799, -2.0795,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0798, -2.0800, -2.0798,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         ...,\n",
              "         [-2.0772, -2.0777, -2.0777,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0795, -2.0791, -2.0795,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0798, -2.0792, -2.0791,  ..., -2.0794, -2.0794, -2.0794]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-2.0786, -2.0785, -2.0787,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0790, -2.0788, -2.0793,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0787, -2.0786, -2.0788,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         ...,\n",
              "         [-2.0817, -2.0816, -2.0817,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0800, -2.0797, -2.0792,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0800, -2.0808, -2.0796,  ..., -2.0794, -2.0794, -2.0794]],\n",
              "\n",
              "        [[-2.0794, -2.0794, -2.0794,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0796, -2.0795, -2.0796,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0794, -2.0794, -2.0792,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         ...,\n",
              "         [-2.0797, -2.0795, -2.0797,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0798, -2.0797, -2.0797,  ..., -2.0794, -2.0794, -2.0794],\n",
              "         [-2.0790, -2.0794, -2.0787,  ..., -2.0794, -2.0794, -2.0794]],\n",
              "\n",
              "        [[-2.0795, -2.0795, -2.0791,  ..., -2.0795, -2.0794, -2.0794],\n",
              "         [-2.0793, -2.0794, -2.0796,  ..., -2.0795, -2.0794, -2.0794],\n",
              "         [-2.0794, -2.0794, -2.0791,  ..., -2.0795, -2.0794, -2.0794],\n",
              "         ...,\n",
              "         [-2.0790, -2.0792, -2.0802,  ..., -2.0795, -2.0794, -2.0794],\n",
              "         [-2.0797, -2.0799, -2.0798,  ..., -2.0795, -2.0794, -2.0794],\n",
              "         [-2.0789, -2.0787, -2.0789,  ..., -2.0795, -2.0794, -2.0794]]],\n",
              "       device='cuda:0', grad_fn=<TransposeBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXa_rFNwo-B7",
        "outputId": "fbb58e0a-eedd-4133-b1b7-2d8223be5f0d"
      },
      "source": [
        "out1.shape"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([8, 31, 671])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBX7w1W5pfbo",
        "outputId": "07fac9a1-91da-4a1e-9368-c62566085c70"
      },
      "source": [
        "out1"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0026,  0.0026,  0.0024,  ...,  0.0020,  0.0024,  0.0023],\n",
              "         [-0.0086, -0.0087, -0.0086,  ..., -0.0088, -0.0089, -0.0087],\n",
              "         [ 0.0113,  0.0115,  0.0115,  ...,  0.0089,  0.0088,  0.0087],\n",
              "         ...,\n",
              "         [ 0.0057,  0.0054,  0.0055,  ...,  0.0050,  0.0047,  0.0048],\n",
              "         [-0.0061, -0.0064, -0.0064,  ..., -0.0058, -0.0060, -0.0061],\n",
              "         [-0.0313, -0.0308, -0.0304,  ..., -0.0310, -0.0309, -0.0313]],\n",
              "\n",
              "        [[ 0.0027,  0.0024,  0.0024,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0085, -0.0086, -0.0087,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0112,  0.0112,  0.0112,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0055,  0.0054,  0.0053,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0061, -0.0062, -0.0064,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0311, -0.0310, -0.0305,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        [[ 0.0030,  0.0028,  0.0025,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0082, -0.0085, -0.0088,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0111,  0.0113,  0.0112,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0056,  0.0055,  0.0054,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0063, -0.0062, -0.0063,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0309, -0.0307, -0.0303,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.0023,  0.0025,  0.0025,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0085, -0.0089, -0.0091,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0115,  0.0113,  0.0111,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0054,  0.0052,  0.0051,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0067, -0.0069, -0.0068,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0306, -0.0305, -0.0299,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        [[ 0.0028,  0.0025,  0.0026,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0085, -0.0085, -0.0085,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0112,  0.0111,  0.0111,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0054,  0.0053,  0.0055,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0062, -0.0062, -0.0064,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0310, -0.0308, -0.0303,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        [[ 0.0029,  0.0026,  0.0026,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0082, -0.0086, -0.0088,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0114,  0.0114,  0.0116,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0055,  0.0055,  0.0052,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0064, -0.0061, -0.0061,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0309, -0.0309, -0.0307,  ..., -0.0308, -0.0310, -0.0314]]],\n",
              "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3qbSnXXphvb"
      },
      "source": [
        "lgsftmx = nn.LogSoftmax(dim=1)\n",
        "sftmx = nn.Softmax(dim=1)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2QUj9mwZptUS",
        "outputId": "fcc1f7df-b7e2-4504-91f1-5c54d7d153ab"
      },
      "source": [
        "lgsftmx(out1)"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.4290, -3.4290, -3.4292,  ..., -3.4296, -3.4292, -3.4293],\n",
              "         [-3.4402, -3.4403, -3.4402,  ..., -3.4404, -3.4405, -3.4404],\n",
              "         [-3.4203, -3.4201, -3.4201,  ..., -3.4227, -3.4228, -3.4229],\n",
              "         ...,\n",
              "         [-3.4259, -3.4263, -3.4261,  ..., -3.4267, -3.4269, -3.4268],\n",
              "         [-3.4378, -3.4380, -3.4380,  ..., -3.4374, -3.4376, -3.4377],\n",
              "         [-3.4629, -3.4624, -3.4620,  ..., -3.4626, -3.4625, -3.4629]],\n",
              "\n",
              "        [[-3.4289, -3.4291, -3.4292,  ..., -3.4296, -3.4293, -3.4294],\n",
              "         [-3.4401, -3.4401, -3.4403,  ..., -3.4407, -3.4406, -3.4404],\n",
              "         [-3.4204, -3.4204, -3.4204,  ..., -3.4226, -3.4227, -3.4229],\n",
              "         ...,\n",
              "         [-3.4261, -3.4262, -3.4262,  ..., -3.4266, -3.4268, -3.4267],\n",
              "         [-3.4377, -3.4378, -3.4380,  ..., -3.4376, -3.4378, -3.4378],\n",
              "         [-3.4627, -3.4626, -3.4621,  ..., -3.4624, -3.4626, -3.4629]],\n",
              "\n",
              "        [[-3.4286, -3.4288, -3.4291,  ..., -3.4296, -3.4293, -3.4294],\n",
              "         [-3.4399, -3.4401, -3.4404,  ..., -3.4407, -3.4406, -3.4404],\n",
              "         [-3.4205, -3.4203, -3.4204,  ..., -3.4226, -3.4227, -3.4229],\n",
              "         ...,\n",
              "         [-3.4260, -3.4261, -3.4262,  ..., -3.4266, -3.4268, -3.4267],\n",
              "         [-3.4379, -3.4378, -3.4379,  ..., -3.4376, -3.4378, -3.4378],\n",
              "         [-3.4625, -3.4623, -3.4618,  ..., -3.4624, -3.4626, -3.4629]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-3.4293, -3.4292, -3.4290,  ..., -3.4296, -3.4293, -3.4294],\n",
              "         [-3.4402, -3.4405, -3.4406,  ..., -3.4407, -3.4406, -3.4404],\n",
              "         [-3.4202, -3.4203, -3.4204,  ..., -3.4226, -3.4227, -3.4229],\n",
              "         ...,\n",
              "         [-3.4263, -3.4265, -3.4265,  ..., -3.4266, -3.4268, -3.4267],\n",
              "         [-3.4383, -3.4385, -3.4384,  ..., -3.4376, -3.4378, -3.4378],\n",
              "         [-3.4622, -3.4621, -3.4615,  ..., -3.4624, -3.4626, -3.4629]],\n",
              "\n",
              "        [[-3.4288, -3.4291, -3.4290,  ..., -3.4296, -3.4293, -3.4294],\n",
              "         [-3.4401, -3.4401, -3.4401,  ..., -3.4407, -3.4406, -3.4404],\n",
              "         [-3.4204, -3.4205, -3.4205,  ..., -3.4226, -3.4227, -3.4229],\n",
              "         ...,\n",
              "         [-3.4262, -3.4263, -3.4261,  ..., -3.4266, -3.4268, -3.4267],\n",
              "         [-3.4379, -3.4378, -3.4380,  ..., -3.4376, -3.4378, -3.4378],\n",
              "         [-3.4626, -3.4623, -3.4619,  ..., -3.4624, -3.4626, -3.4629]],\n",
              "\n",
              "        [[-3.4287, -3.4290, -3.4290,  ..., -3.4296, -3.4293, -3.4294],\n",
              "         [-3.4399, -3.4403, -3.4404,  ..., -3.4407, -3.4406, -3.4404],\n",
              "         [-3.4203, -3.4202, -3.4200,  ..., -3.4226, -3.4227, -3.4229],\n",
              "         ...,\n",
              "         [-3.4262, -3.4262, -3.4264,  ..., -3.4266, -3.4268, -3.4267],\n",
              "         [-3.4380, -3.4377, -3.4377,  ..., -3.4376, -3.4378, -3.4378],\n",
              "         [-3.4626, -3.4625, -3.4623,  ..., -3.4624, -3.4626, -3.4629]]],\n",
              "       device='cuda:0', grad_fn=<LogSoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8TMo9Znpuek",
        "outputId": "e1705b97-4b50-4256-f28a-c280aaabf759"
      },
      "source": [
        "sftmx(out1)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.0324, 0.0324, 0.0324,  ..., 0.0324, 0.0324, 0.0324],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0321, 0.0320, 0.0321],\n",
              "         [0.0327, 0.0327, 0.0327,  ..., 0.0326, 0.0326, 0.0326],\n",
              "         ...,\n",
              "         [0.0325, 0.0325, 0.0325,  ..., 0.0325, 0.0325, 0.0325],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0321, 0.0321, 0.0321],\n",
              "         [0.0313, 0.0314, 0.0314,  ..., 0.0313, 0.0314, 0.0313]],\n",
              "\n",
              "        [[0.0324, 0.0324, 0.0324,  ..., 0.0324, 0.0324, 0.0324],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0320, 0.0320, 0.0321],\n",
              "         [0.0327, 0.0327, 0.0327,  ..., 0.0326, 0.0326, 0.0326],\n",
              "         ...,\n",
              "         [0.0325, 0.0325, 0.0325,  ..., 0.0325, 0.0325, 0.0325],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0321, 0.0321, 0.0321],\n",
              "         [0.0313, 0.0313, 0.0314,  ..., 0.0314, 0.0313, 0.0313]],\n",
              "\n",
              "        [[0.0324, 0.0324, 0.0324,  ..., 0.0324, 0.0324, 0.0324],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0320, 0.0320, 0.0321],\n",
              "         [0.0327, 0.0327, 0.0327,  ..., 0.0326, 0.0326, 0.0326],\n",
              "         ...,\n",
              "         [0.0325, 0.0325, 0.0325,  ..., 0.0325, 0.0325, 0.0325],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0321, 0.0321, 0.0321],\n",
              "         [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0313, 0.0313]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.0324, 0.0324, 0.0324,  ..., 0.0324, 0.0324, 0.0324],\n",
              "         [0.0321, 0.0320, 0.0320,  ..., 0.0320, 0.0320, 0.0321],\n",
              "         [0.0327, 0.0327, 0.0327,  ..., 0.0326, 0.0326, 0.0326],\n",
              "         ...,\n",
              "         [0.0325, 0.0325, 0.0325,  ..., 0.0325, 0.0325, 0.0325],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0321, 0.0321, 0.0321],\n",
              "         [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0313, 0.0313]],\n",
              "\n",
              "        [[0.0324, 0.0324, 0.0324,  ..., 0.0324, 0.0324, 0.0324],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0320, 0.0320, 0.0321],\n",
              "         [0.0327, 0.0327, 0.0327,  ..., 0.0326, 0.0326, 0.0326],\n",
              "         ...,\n",
              "         [0.0325, 0.0325, 0.0325,  ..., 0.0325, 0.0325, 0.0325],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0321, 0.0321, 0.0321],\n",
              "         [0.0313, 0.0314, 0.0314,  ..., 0.0314, 0.0313, 0.0313]],\n",
              "\n",
              "        [[0.0324, 0.0324, 0.0324,  ..., 0.0324, 0.0324, 0.0324],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0320, 0.0320, 0.0321],\n",
              "         [0.0327, 0.0327, 0.0327,  ..., 0.0326, 0.0326, 0.0326],\n",
              "         ...,\n",
              "         [0.0325, 0.0325, 0.0325,  ..., 0.0325, 0.0325, 0.0325],\n",
              "         [0.0321, 0.0321, 0.0321,  ..., 0.0321, 0.0321, 0.0321],\n",
              "         [0.0313, 0.0314, 0.0314,  ..., 0.0314, 0.0313, 0.0313]]],\n",
              "       device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nF6tlz9Hp5kU",
        "outputId": "6a170ffa-e7b7-4992-b811-9e4e82edf11a"
      },
      "source": [
        "out1"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0.0026,  0.0026,  0.0024,  ...,  0.0020,  0.0024,  0.0023],\n",
              "         [-0.0086, -0.0087, -0.0086,  ..., -0.0088, -0.0089, -0.0087],\n",
              "         [ 0.0113,  0.0115,  0.0115,  ...,  0.0089,  0.0088,  0.0087],\n",
              "         ...,\n",
              "         [ 0.0057,  0.0054,  0.0055,  ...,  0.0050,  0.0047,  0.0048],\n",
              "         [-0.0061, -0.0064, -0.0064,  ..., -0.0058, -0.0060, -0.0061],\n",
              "         [-0.0313, -0.0308, -0.0304,  ..., -0.0310, -0.0309, -0.0313]],\n",
              "\n",
              "        [[ 0.0027,  0.0024,  0.0024,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0085, -0.0086, -0.0087,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0112,  0.0112,  0.0112,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0055,  0.0054,  0.0053,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0061, -0.0062, -0.0064,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0311, -0.0310, -0.0305,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        [[ 0.0030,  0.0028,  0.0025,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0082, -0.0085, -0.0088,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0111,  0.0113,  0.0112,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0056,  0.0055,  0.0054,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0063, -0.0062, -0.0063,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0309, -0.0307, -0.0303,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.0023,  0.0025,  0.0025,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0085, -0.0089, -0.0091,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0115,  0.0113,  0.0111,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0054,  0.0052,  0.0051,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0067, -0.0069, -0.0068,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0306, -0.0305, -0.0299,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        [[ 0.0028,  0.0025,  0.0026,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0085, -0.0085, -0.0085,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0112,  0.0111,  0.0111,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0054,  0.0053,  0.0055,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0062, -0.0062, -0.0064,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0310, -0.0308, -0.0303,  ..., -0.0308, -0.0310, -0.0314]],\n",
              "\n",
              "        [[ 0.0029,  0.0026,  0.0026,  ...,  0.0020,  0.0023,  0.0022],\n",
              "         [-0.0082, -0.0086, -0.0088,  ..., -0.0091, -0.0090, -0.0088],\n",
              "         [ 0.0114,  0.0114,  0.0116,  ...,  0.0089,  0.0088,  0.0086],\n",
              "         ...,\n",
              "         [ 0.0055,  0.0055,  0.0052,  ...,  0.0050,  0.0048,  0.0048],\n",
              "         [-0.0064, -0.0061, -0.0061,  ..., -0.0060, -0.0062, -0.0063],\n",
              "         [-0.0309, -0.0309, -0.0307,  ..., -0.0308, -0.0310, -0.0314]]],\n",
              "       device='cuda:0', grad_fn=<SqueezeBackward1>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uikSoEap73Y",
        "outputId": "6ac66f91-fea5-487a-c7a9-c1c1a60ad019"
      },
      "source": [
        "inputs[0].max(dim=1)"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.return_types.max(values=tensor([ 10,  37,  99, 152,  48,  93, 149, 267, 184,  69,  60,  17,  25,  22,\n",
              "         30,  17,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,  47,  35,  27,  14,  13,  43,  28,  12,   8,  14],\n",
              "       device='cuda:0'), ...)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVSa36N3scil",
        "outputId": "e8e1aa75-a5b0-4c8c-84b6-5b7ada2cd2c7"
      },
      "source": [
        "global_feats = np.zeros(40)\n",
        "gloabl_std = np.zeros(40)\n",
        "for i, x in enumerate(train_data.X):\n",
        "  global_mean += np.mean(x, 1)\n"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(40,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1S9d4B4fsppR"
      },
      "source": [
        "tmp_ = np.concatenate(train_data.X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guirkgc7tkOw"
      },
      "source": [
        "tmp_.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a9slJsIpcNG"
      },
      "source": [
        "criterion = nn.CTCLoss().to(device)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_-neTUrtli3"
      },
      "source": [
        "loss = criterion(out, targets, out_lengths, target_lengths)"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBKzsD8npTqv",
        "outputId": "5d746b9a-d481-4a5d-c7c1-257719b5e48e"
      },
      "source": [
        "loss.item()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "nan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8sHm1PMpUUZ",
        "outputId": "98315dc1-6915-4d67-e039-37ef6d858ad6"
      },
      "source": [
        "out.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 8, 630])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kj_cuTZVpfFF",
        "outputId": "f6a648b7-324e-4266-db6b-e9335f021dfb"
      },
      "source": [
        "targets"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3,  6,  8,  ...,  0,  0,  0],\n",
              "        [ 3, 18, 10,  ..., 19,  5, 10],\n",
              "        [ 3, 21,  7,  ...,  0,  0,  0],\n",
              "        ...,\n",
              "        [ 3, 20,  4,  ...,  0,  0,  0],\n",
              "        [ 3, 17,  6,  ...,  0,  0,  0],\n",
              "        [ 3,  9,  5,  ...,  0,  0,  0]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULebx6o8pg2c",
        "outputId": "2f96cf96-5f0c-4bf7-f9a6-ded4818f36bd"
      },
      "source": [
        "out_lengths"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([32, 29, 13, 17, 25, 29, 27, 17], dtype=torch.int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrg-E3hRp9cw",
        "outputId": "6bc7e10d-23f3-458b-fe0d-018f9417bc60"
      },
      "source": [
        "inputs.dtype"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RNLVNQoHy64N"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}