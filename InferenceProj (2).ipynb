{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../HW4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_spectrograms_path = './data/dev.npy'\n",
    "dev_labels_path = './data/dev_transcripts_cleaned.txt'\n",
    "\n",
    "test_spectrograms_path = './data/test.npy'\n",
    "test_labels_path = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing all the required libraries. \n",
    "import torch # Deep Learning Framework\n",
    "import torch.nn as nn\n",
    "import torchaudio # to use the time masking and frequency masking - specaug for regularizing the models\n",
    "import time # to keep track of the time for each pass and iteration\n",
    "import numpy as np # array manipulating library\n",
    "\n",
    "from tqdm.notebook import tqdm # to see the proress bar for prediction :p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ctcdecode import CTCBeamDecoder # github:parlance/ctcdecode; For beam decoding the model.\n",
    "import Levenshtein # to measure the edit distance of the prediction from ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration = {\n",
    "    'batchsize':32, \n",
    "    'learning_rate':5e-4,\n",
    "    'weight_decay':5e-5,\n",
    "    'freq_masking':[3, 10], # frequency masking\n",
    "    'time_masking':[2, 40], # time masking\n",
    "    'num_workers':4, # for multithreading/processing the dataloader. \n",
    "    'cuda':True, # I have a GPU :P\n",
    "    'num_processes':os.cpu_count(), # This is for the Batch Beam Decoding\n",
    "    'experiment_name':'Wav2letterProj_002' # final model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda and cuda available: True\n"
     ]
    }
   ],
   "source": [
    "CUDA = configuration['cuda']\n",
    "DEVICE = torch.device('cuda') if CUDA else torch.device('cpu')\n",
    "print(f\"Using device: {DEVICE} and cuda available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique characters in the token set:  34\n"
     ]
    }
   ],
   "source": [
    "label_map = ['<sos>', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '-', \"'\", '.', '_', '+', ' ', '<eos>']\n",
    "label_map_c2i = {c:i for i, c in enumerate(label_map)}\n",
    "print(\"Total unique characters in the token set: \", len(label_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLANK_TAG = '<b>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "dev_audio_transforms = None\n",
    "test_audio_transforms = None\n",
    "\n",
    "print(dev_audio_transforms)\n",
    "print(test_audio_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HW4P2datasetProj(torch.utils.data.Dataset):\n",
    "    def __init__(self, infile, outfile=None, label_map_c2i=None, transforms=None):\n",
    "        stime = time.time()\n",
    "        self.spectrograms = np.load(infile, allow_pickle=True)\n",
    "        print(f\"Spectrograms-> {infile} -> {len(self.spectrograms)}\")\n",
    "        self.labels = None\n",
    "        self.label_map_c2i = label_map_c2i\n",
    "        if outfile is not None:\n",
    "            with open(outfile) as file:\n",
    "                self.labels = [] \n",
    "                for line in file.read().splitlines():\n",
    "                    labels = [] \n",
    "                    for s in line:\n",
    "                        labels.append(self.label_map_c2i[s])\n",
    "                    self.labels.append(labels)\n",
    "            print(f\"Labels-> {outfile} -> {len(self.labels)}\")\n",
    "        self.transforms = transforms\n",
    "        etime = time.time()\n",
    "        print(f\"Loaded in {etime-stime:3.3f} secs\")\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.spectrograms)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        spectrogram = torch.from_numpy(self.spectrograms[idx]).float()\n",
    "        if self.transforms is not None:\n",
    "            spectrogram = self.transforms(spectrogram.T).T\n",
    "        if self.labels is None:\n",
    "            label = torch.from_numpy(np.array([-1])).int()\n",
    "        else:\n",
    "            label = torch.from_numpy(np.array(self.labels[idx])).int() # adding 0 to compensate the blank in CTC\n",
    "        return spectrogram, label\n",
    "\n",
    "def collate_function(batch):\n",
    "    spectrograms = []\n",
    "    spectrograms_lens = []\n",
    "    labels = []\n",
    "    labels_lens = []\n",
    "    for b in batch:\n",
    "        spectrograms.append(b[0])\n",
    "        spectrograms_lens.append(len(b[0]))\n",
    "        labels.append(b[1])\n",
    "        labels_lens.append(len(b[1]))\n",
    "    spectrograms_ = torch.nn.utils.rnn.pad_sequence(spectrograms, batch_first=True) \n",
    "    labels_ = torch.nn.utils.rnn.pad_sequence(labels, batch_first=True)\n",
    "    spectrograms_lens = torch.LongTensor(spectrograms_lens)\n",
    "    len_ratios = spectrograms_lens/max(spectrograms_lens)\n",
    "    return spectrograms_, labels_, spectrograms_lens, torch.LongTensor(labels_lens), len_ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrograms-> ./data/dev.npy -> 2703\n",
      "Labels-> ./data/dev_transcripts_cleaned.txt -> 2703\n",
      "Loaded in 0.200 secs\n",
      "Spectrograms-> ./data/test.npy -> 2620\n",
      "Loaded in 0.142 secs\n"
     ]
    }
   ],
   "source": [
    "dev_dataset = HW4P2datasetProj(infile=dev_spectrograms_path, \n",
    "                               outfile=dev_labels_path, \n",
    "                               label_map_c2i=label_map_c2i,\n",
    "                               transforms=dev_audio_transforms)\n",
    "\n",
    "test_dataset = HW4P2datasetProj(infile=test_spectrograms_path, \n",
    "                                outfile=test_labels_path,  \n",
    "                                label_map_c2i=label_map_c2i, \n",
    "                                transforms=test_audio_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = torch.utils.data.DataLoader(dev_dataset, \n",
    "                                       shuffle=True,\n",
    "                                       batch_size=configuration['batchsize'],\n",
    "                                       collate_fn=collate_function,\n",
    "                                       num_workers=configuration['num_workers'],\n",
    "                                       pin_memory=True)\n",
    "test_data = torch.utils.data.DataLoader(test_dataset, \n",
    "                                        shuffle=False, \n",
    "                                        batch_size=configuration['batchsize'],\n",
    "                                        collate_fn=collate_function,\n",
    "                                        num_workers=configuration['num_workers'],\n",
    "                                        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to help in various small trivial tasks\n",
    "class HelperFns:\n",
    "    def __init__(self, label_map, label_map_c2i):\n",
    "        self.label_map = label_map\n",
    "        self.label_map_c2i = label_map_c2i\n",
    "        self.distance = Levenshtein.distance\n",
    "        \n",
    "    def convertID2Sentence(self, I):\n",
    "        sentence = \"\"\n",
    "        for i in I: \n",
    "            sentence += self.label_map[i]\n",
    "        return self.normalizeS(sentence)\n",
    "    \n",
    "    def convertID2SentenceRaw(self, I):\n",
    "        sentence = \"\"\n",
    "        for i in I:\n",
    "            try:\n",
    "                sentence += self.label_map[i]\n",
    "            except Exception as e:\n",
    "                sentence += BLANK_TAG\n",
    "        return self.normalizeS(sentence)\n",
    "    \n",
    "    def calculate_cer(self, S1, S2):\n",
    "        return self.distance(self.normalizeS(S1), self.normalizeS(S2))\n",
    "    \n",
    "    def normalizeS(self, S):\n",
    "        return S.replace(BLANK_TAG, \"\").replace('<sos>', \"\").replace('<eos>', \"\").strip()\n",
    "    \n",
    "    def convertSentence2IDs(self, sentence):\n",
    "        Ids = []\n",
    "        for s in sentence:\n",
    "            Ids.append(self.label_map_c2i[s])\n",
    "        return Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper = HelperFns(label_map, label_map_c2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 8, 9, 19, 32, 9, 19, 32, 1, 32, 20, 5, 19, 20, 32, 19, 5, 14, 20, 5, 14, 3, 5]\n",
      "this is a test sentence\n"
     ]
    }
   ],
   "source": [
    "t_ = helper.convertSentence2IDs('this is a test sentence')\n",
    "print(t_)\n",
    "print(helper.convertID2SentenceRaw(t_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_logits(logits, data_lens, beam_width=1):\n",
    "    ctc_decoder = CTCBeamDecoder(labels=label_map + [BLANK_TAG], \n",
    "                                 beam_width=beam_width, \n",
    "                                 num_processes=configuration['num_processes'],\n",
    "                                 log_probs_input=True)\n",
    "    beam_results, beam_scores, timesteps, out_lens = ctc_decoder.decode(logits.permute(1, 0, 2), data_lens)\n",
    "    decoded_transcripts = []\n",
    "    for i, (beam_result, out_len) in enumerate(zip(beam_results, out_lens)):\n",
    "        transcript = \"\"\n",
    "        if out_len[0]>0: \n",
    "            transcript = helper.convertID2SentenceRaw((beam_result[0, :out_len[0]].numpy()).tolist()) #\"\".join([label_map[i] for i in beam_result[0, :out_len[0]]])\n",
    "        decoded_transcripts.append(transcript)\n",
    "    return decoded_transcripts\n",
    "\n",
    "@torch.no_grad()\n",
    "def test_model(model, data, loss, current_epoch=1, decode=False, beam_width=1):\n",
    "    model.eval()\n",
    "    stime = time.time()\n",
    "    len_data = len(data)\n",
    "    print(f\"Started Testing Epoch: {current_epoch}\")\n",
    "    total_loss = 0.0\n",
    "    average_cer = 0.0\n",
    "    nexamples = 0\n",
    "    outwriterfile = open(f'sample_decodes.txt', 'w')\n",
    "    for i, batch in enumerate(data):\n",
    "        spectrograms = batch[0].to(DEVICE)\n",
    "        labels = batch[1].to(DEVICE)\n",
    "        spectrograms_lens = batch[2].to(DEVICE)\n",
    "        labels_lens = batch[3].to(DEVICE)\n",
    "        input_len_ratio = batch[4].to(DEVICE)\n",
    "        output_logits = model(spectrograms) \n",
    "        seq_length = output_logits.size(0)\n",
    "        output_lens = torch.autograd.Variable(input_len_ratio.mul_(int(seq_length)).int(), requires_grad=False)\n",
    "        \n",
    "        l = loss(output_logits, labels.cpu(), output_lens.cpu(), labels_lens.cpu())\n",
    "        # its efficient to decode the transcripts while we have the model predictions. \n",
    "        if decode:\n",
    "            decoded_transcripts = decode_logits(output_logits, output_lens, beam_width=beam_width)\n",
    "            for ii, (decoded_transcipt, label) in enumerate(zip(decoded_transcripts, labels)):\n",
    "                nexamples += 1\n",
    "                label_string = helper.convertID2SentenceRaw((label[:labels_lens[ii]].cpu().numpy()).tolist())\n",
    "                CER = helper.calculate_cer(decoded_transcipt, label_string)\n",
    "                average_cer += CER\n",
    "                print(f\"{nexamples} label_string: {label_string}\", file=outwriterfile)\n",
    "                print(f\"{nexamples} decoded_transcript: {decoded_transcipt}\", file=outwriterfile)\n",
    "                print(f\"{nexamples} cer: {CER}\\n\", file=outwriterfile)\n",
    "                \n",
    "        if i%50==0:\n",
    "            if decode:\n",
    "                print(f'\\tE:{current_epoch}\\tBatch:{i}/{len_data}\\tLoss: {l.item():3.3f}\\tcer: {average_cer/nexamples}\\tTelapsed:{time.time()-stime:3.3f} Secs')\n",
    "            else:\n",
    "                print(f'\\tE:{current_epoch}\\tBatch:{i}/{len_data}\\tLoss: {l.item():3.3f}\\tTelapsed:{time.time()-stime:3.3f} Secs')\n",
    "        total_loss += l.item()\n",
    "        torch.cuda.empty_cache()\n",
    "        del spectrograms\n",
    "        del labels\n",
    "        del spectrograms_lens\n",
    "        del labels_lens\n",
    "    outwriterfile.close()\n",
    "    etime = time.time()\n",
    "    if not decode:\n",
    "        print(f\"Completed Testing Epoch: Loss: {total_loss/len_data}\\tTime: {etime-stime:3.3f} Secs\")\n",
    "    else:\n",
    "        print(f\"Completed Testing Epoch: Loss: {total_loss/len_data}\\tCER:{average_cer/nexamples}\\tTime: {etime-stime:3.3f} Secs\")\n",
    "    return total_loss/len_data, average_cer/(1e-16+nexamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def get_predictions(model, data, beam_width=1):\n",
    "    model.eval()\n",
    "    stime = time.time()\n",
    "    len_data = len(data)\n",
    "    print(f\"Getting Predictions on {len_data} files\")\n",
    "    all_transcripts = []\n",
    "    for i, batch in enumerate(tqdm(data)):\n",
    "        spectrograms = batch[0].to(DEVICE)\n",
    "        output_logits = model(spectrograms)\n",
    "        input_len_ratio = batch[4].to(DEVICE)\n",
    "        output_logits = model(spectrograms) \n",
    "        seq_length = output_logits.size(0)\n",
    "        output_lens = torch.autograd.Variable(input_len_ratio.mul_(int(seq_length)).int(), requires_grad=False)\n",
    "        decoded_transcripts = decode_logits(output_logits, output_lens, beam_width=beam_width)\n",
    "        all_transcripts.extend(decoded_transcripts)\n",
    "        torch.cuda.empty_cache()\n",
    "        del spectrograms\n",
    "    return all_transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.dropout(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class Wav2Letter(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, num_features = 40):\n",
    "        super(Wav2Letter, self).__init__()\n",
    "\n",
    "        model = nn.Sequential(\n",
    "            ConvBlock(in_channels=num_features, out_channels=250, kernel_size=48, stride=2, padding=23),\n",
    "\n",
    "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
    "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
    "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
    "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
    "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
    "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
    "            ConvBlock(in_channels=250, out_channels=250, kernel_size=7, stride=1, padding=3),\n",
    "\n",
    "            ConvBlock(in_channels=250, out_channels=2000, kernel_size=32, stride=1, padding=16),\n",
    "            ConvBlock(in_channels=2000, out_channels=2000, kernel_size=1, stride=1, padding=0),\n",
    "            nn.Conv1d(in_channels=2000, out_channels=num_classes, kernel_size=1, stride=1, padding=0)\n",
    "        )\n",
    "        \n",
    "        self.model = model\n",
    "        self.log_softmax = nn.LogSoftmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x - # (batch_size, input_length, num_features)\n",
    "        out = self.model(x.permute(0, 2, 1)) # (batch_size, num_features, input_length)\n",
    "        out = self.log_softmax(out) # applies on num_features(num_classes)\n",
    "        return out.permute(2, 0, 1) # (batch_size, input_length, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wav2Letter(\n",
       "  (model): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (conv): Conv1d(40, 250, kernel_size=(48,), stride=(2,), padding=(23,))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (3): ConvBlock(\n",
       "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (4): ConvBlock(\n",
       "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (5): ConvBlock(\n",
       "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (6): ConvBlock(\n",
       "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (7): ConvBlock(\n",
       "      (conv): Conv1d(250, 250, kernel_size=(7,), stride=(1,), padding=(3,))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (8): ConvBlock(\n",
       "      (conv): Conv1d(250, 2000, kernel_size=(32,), stride=(1,), padding=(16,))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (9): ConvBlock(\n",
       "      (conv): Conv1d(2000, 2000, kernel_size=(1,), stride=(1,))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (10): Conv1d(2000, 35, kernel_size=(1,), stride=(1,))\n",
       "  )\n",
       "  (log_softmax): LogSoftmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =  Wav2Letter(len(label_map) + 1) # this is for the blank character\n",
    "model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mdl = torch.load('./models/wav2letter_31.pth')\n",
    "model.load_state_dict(mdl.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = torch.nn.CTCLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started Testing Epoch: 1\n",
      "\tE:1\tBatch:0/85\tLoss: 1.286\tcer: 34.78125\tTelapsed:0.367 Secs\n",
      "\tE:1\tBatch:50/85\tLoss: 1.298\tcer: 32.099877450980394\tTelapsed:11.833 Secs\n",
      "Completed Testing Epoch: Loss: 1.256102619451635\tCER:31.69515353311136\tTime: 19.261 Secs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1.256102619451635, 31.69515353311136)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model, dev_data, loss, decode=True, beam_width=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting Predictions on 82 files\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8ec6db2e024a20ab2a60786f6c01fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=82.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "preds = get_predictions(model, test_data, beam_width=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yes serdary the trembling for ing holsh for this dears the yeu to day you see a for geur olle to mar alwayfulden anxety about  monney the day after to morrow the di atfi of a slan er the day afk ter that the missforture of some find then the prevaling weather then something that is been built in ther waws thenn aleazerly whul ster concence san year bur ol colm re hot youyou again the course of public affairs',\n",
       " 'we were wor intersta ed sent lical condition of the station lat in the comersalbiy',\n",
       " 'ih saw but i mest at money to be bhat what',\n",
       " \"in  re gards y brabbing the compry i'l say that i saye tare heavy last one day\",\n",
       " 'but they to te i acprortin a dase against lacy that she was innosa ano thers trots of the resten hoverpropy of the blefh',\n",
       " 'the wil human division is this to meminus and mis saety',\n",
       " 'almost instanly wast forced to the topk',\n",
       " 'as that he wonderf she could laugh about it wilh e now',\n",
       " \"and thi tay i don'tknow mur tod at thedain of ae\",\n",
       " 'fa  hunded min more he had been lobyed by the comin intas were desuated tongrace the ron colers and wid this convi for see hatened to attantt yourd elcan who li at pass with an ally of six thousand ain asimbled upon the fist news of the orish invasion',\n",
       " 'in te motta bo constected by he soudgiringd up animotin a en viite imposin wheth he a fined the do it anything be mor migte',\n",
       " 'it was spetually suoted for a child pliet also in the early days when he ye olde spict or eigh glance for the horse til her was consider subdec for kon raguaon',\n",
       " 'at ins inde crom that them portencs of tack andthe skill in the traning of the young and nof cultivating their reason and saf carring their affection had not the orratd',\n",
       " 'exsen las bans were ling around the sprem the awfluls o adear e scattered about the place and he trees wore evident marks of having been browse by the horse es',\n",
       " \"why vanister the servant what's is game in the nack\",\n",
       " 'there testinte is car thers however desplay one broae in  hun failing difference',\n",
       " 'tuse to dispe op pontes orosion',\n",
       " 'ohdo oxammin this curious contraens with wonder',\n",
       " 'gentleman der poasts were uponsand anyon andgilar i too tairly',\n",
       " 'the came upon theasup jop when i heard le tords whuc exceeded anything which i ae yet self']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TorchK",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
